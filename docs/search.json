[
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\nUntil now!\nA new change here.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.0.1 About you\nI assume that you are familiar with the general linear model (although we will have a refresher) - my aim is not to cover things that you will find in a general undergraduate or postgrad methods course on statistical modelling, but focus on a set of illustratons of specific problems that can arise in some criminological contexts. I’ve tried to pick examples that are both specific enough to be illuminating, but general enough that the techniques I’ll desribe (of say simulating quantities of interest from your fitted model) are generally relevant. No guarantees though. Hopefully act as inspiration when grappling with your own analytical problems.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Atak, Kıvanç. 2020. “Beyond the Western Crime Drop:\nViolence, Property Offences, and the State in\nTurkey 19902016.” International\nJournal of Law, Crime and Justice 60 (March): 100373. https://doi.org/10.1016/j.ijlcj.2019.100373.\n\n\nBuil-Gil, David, Ian Brunton-Smith, Jose Pina-Sánchez, and Alexandru\nCernat. 2022. “Comparing Measurements of Violent Crime in Local\nCommunities: A Case Study in Islington,\nLondon.” Police Practice and Research 23\n(4): 489–506. https://doi.org/10.1080/15614263.2022.2047047.\n\n\nCarr-Hill, Roy. 2013. “Missing Millions and\nMeasuring Development Progress.” World\nDevelopment 46 (June): 30–44. https://doi.org/10.1016/j.worlddev.2012.12.017.\n\n\nGaebler, Johann, William Cai, Guillaume Basse, Ravi Shroff, Sharad Goel,\nand Jennifer Hill. 2022. “A Causal Framework for\nObservational Studies of\nDiscrimination.” Statistics and Public\nPolicy 9 (1): 26–48. https://doi.org/10.1080/2330443X.2021.2024778.\n\n\nGreenland, Sander. 2014. “Sensitivity Analysis and\nBias Analysis.” In Handbook of\nEpidemiology, edited by Wolfgang Ahrens and Iris\nPigeot, 685–706. New York, NY: Springer. https://doi.org/10.1007/978-0-387-09834-0_60.\n\n\nKnox, Dean, Will Lowe, and Jonathan Mummolo. 2020. “Administrative\nRecords Mask Racially Biased Policing.” American\nPolitical Science Review 114 (3): 619–37. https://doi.org/10.1017/S0003055420000039.\n\n\nScottish Women’s Aid. 2021. “Response to the Consultation on the\nScottish Crime and Justice Survey\n(SCJS), December 2021.”\nhttps://womensaid.scot/wp-content/uploads/2022/04/SWA-response-to-Scottish-Crime-and-Justice-Survey-consultation.pdf.\n\n\nSimes, Jessica T. 2021. Punishing Places: The\nGeography of Mass Imprisonment. Univ of\nCalifornia Press.\n\n\nSimes, Jessica T. 2018. “Place and Punishment:\nThe Spatial Context of Mass\nIncarceration.” Journal of Quantitative\nCriminology 34 (2): 513–33. https://doi.org/10.1007/s10940-017-9344-y.\n\n\nSimes, Jessica T., Brenden Beck, and John M. Eason. 2023.\n“Policing, Punishment, and Place:\nSpatial-Contextual Analyses of the Criminal Legal\nSystem.” Annual Review of Sociology 49 (1):\n221–40. https://doi.org/10.1146/annurev-soc-031021-035328.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Methods for Criminology",
    "section": "",
    "text": "Preface\nThis website contains the notes and R code for the NCRM workshop ‘Statistical Methods for Criminology’ which will run in September 2024.\nIt is very work in progress.\n\n\nAbout\nThis website contains the notes for the course. This is a combination of theoretical discussion and worked examples of fitting statistical models to criminological data and the issues that can arise when doing so.\nThe worked examples use ode in the R statistical language.\nThis website was built with Quarto using RStudio and is rendered with Github Pages.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "types-of-data.html",
    "href": "types-of-data.html",
    "title": "2  Types of criminological data",
    "section": "",
    "text": "2.1 Who cares about data provenance?\nTo conduct a useful analysis - the kind that might help you understand the real world - you need to understand how your data came about. As we’ll see, whether you are analysing a survey or police recorded crime data or convictions data or something else matters in how you conduct your analysis and interpret the results. You need to know the ‘generative story’1 about your data to analyse it properly.\nWhen working with criminological data we often know quite a lot about how the data (or if you like, the numbers in the spreadsheet in front of you) came to exist. Using this information - information that might be in metadata, or based on our theoretical knowledge of the world - can help us do better data analysis.\nHow exactly we incorporate this information will depend a lot on what data we’re working with and what the goals of our analysis are. There are no general solutions to what information we should incorporate and how we might do this, but in this workshop we’ll cover some scenarios that can arise in criminological research.\n(Keay and Towers 2024, p228–229)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "intro.html#types-of-criminological-data",
    "href": "intro.html#types-of-criminological-data",
    "title": "1  Introduction",
    "section": "1.1 Types of criminological data",
    "text": "1.1 Types of criminological data\n\nSurveys\nPolice\nCourts // I’m sure there’s more\nWhat is the data provenance? What does this mean for my analysis?\nDo I need survey weights? Do I need to account for interactions with officers that aren’t recorded? Do I interpret convictions as a measure of offending?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#the-general-linear-model",
    "href": "intro.html#the-general-linear-model",
    "title": "1  Introduction",
    "section": "1.2 The general linear model",
    "text": "1.2 The general linear model\n\nBig picture: two tribes of modellers?\n\nEconomists versus epidemiologists\n\nWon’t include: mixed/multilevel/hierarchical/etc\nBut these might be relevant!\nFocus on general linear model to think about binary and count outcomes\n\nOver-dispersion what to do?\n\ninferential uncertainty versus outcome variability",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#measurement-error-and-selection-bias",
    "href": "intro.html#measurement-error-and-selection-bias",
    "title": "1  Introduction",
    "section": "1.3 Measurement error and selection bias",
    "text": "1.3 Measurement error and selection bias\n\nJose Pina Sanchez and measurement error\nWalby and volatility over time\nmeasurement error in general - from McElreath (can attenuate, but no guarantees)\nmeasurement error in controls - uh oh\nselection bias\n\nI guess I was thinking about the McElreath paper here/the Knox paper about conditioning on stop\nalso Sander Greenland about everything is conditional on selection into the study (e.g. mortality in prison)\nAnd also can do the Sander Greenland stuff on probabilistic bias analysis",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#ethics-of-working-with-criminological-data",
    "href": "intro.html#ethics-of-working-with-criminological-data",
    "title": "1  Introduction",
    "section": "1.5 Ethics of working with criminological data",
    "text": "1.5 Ethics of working with criminological data\n\nJessica Simes and community loss",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#how-does-an-event-become-a-crime-statistic",
    "href": "types-of-data.html#how-does-an-event-become-a-crime-statistic",
    "title": "3  Types of criminological data",
    "section": "3.3 How does an event become a crime statistic?",
    "text": "3.3 How does an event become a crime statistic?\n[add link to SG flow diagram]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#how-does-an-incident-end-up-as-a-court-record",
    "href": "types-of-data.html#how-does-an-incident-end-up-as-a-court-record",
    "title": "3  Types of criminological data",
    "section": "3.4 How does an incident end up as a court record?",
    "text": "3.4 How does an incident end up as a court record?\nCrime​\nArrest and charge​\nCourt​\nSentencing​",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#how-does-an-incident-get-logged-as-a-police-stop",
    "href": "types-of-data.html#how-does-an-incident-get-logged-as-a-police-stop",
    "title": "3  Types of criminological data",
    "section": "3.5 How does an incident get logged as a police stop?",
    "text": "3.5 How does an incident get logged as a police stop?\n(Knox and Mummolo)\n\nObservation\nEncouter\nStop",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#key-dilemma",
    "href": "types-of-data.html#key-dilemma",
    "title": "2  Types of criminological data",
    "section": "2.3 Key dilemma",
    "text": "2.3 Key dilemma\nDo official crime statistics reflect ‘behavioural’ trends in crime, or just the actions of the justice system?​(Kitsuse and Cicourel, 1963)\nHow you see this may depend on your theoretical persuasion (Simes, Beck, and Eason 2023)\nSometimes this is less of a dilemma when you have a comparable victim survey and you are interested in overall levels of crime (Buil-Gil et al. 2022). However, this is a challenge “outside consolidated western democracies where the range of available data is often limited” (Atak 2020)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#survey-data",
    "href": "types-of-data.html#survey-data",
    "title": "2  Types of criminological data",
    "section": "2.3 Survey data",
    "text": "2.3 Survey data\nIn response to known issues with measuring levels of crime with administrative data, since the 1980s criminologists in some parts of the world have been surveying the public to ask about their levels of victimization.\nScottish Crime and Justice Survey​\nCrime Survey for England and Wales​\nEquivalents in other countries, primarily in Western Europe, North America and Australasia ​\nSmaller geographical scale surveys such as The Mayor’s Office for Policing And Crime (MOPAC) Survey in London",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#victimization-surveys",
    "href": "types-of-data.html#victimization-surveys",
    "title": "2  Types of criminological data",
    "section": "2.4 Victimization surveys",
    "text": "2.4 Victimization surveys\nTypically ask people about their experiences of victimization in the last year​\nCan measure crime that isn’t reported to the police​\nUsually don’t ask about people’s offending behaviour​\nGood for measuring common crimes, bad for measuring rare crimes\n\n2.4.1 Answering our key questions\n\n\n2.4.2 How does a person get selected for the SCJS?\nRandom sample of 12,000ish postcodes in Scotland are contacted to take part​(for 2020/21 survey it was 12,681 addresses)\nFor those who agree, one adult (age 16 or over) in each household is randomly selected for interview​\nTherefore, by design no:​\n\nChildren​\nHomeless people​\nPeople living in communal establishments (e.g. students, people in prison)\n\nThere may also be limitations on who ends up in a survey dataset even if they are included in the design. With a focus on International Development, Carr-Hill says that “in practice, household surveys typically under-represent: those in fragile, disjointed households; slum populations and areas posing security risks.” (Carr-Hill 2013). The extent to which these factors may affect any particular data collection exercise may vary from having little to extreme impact (for example, research being conduct in a conflict zone). It is up to the researcher to determine the likely extent of factors such as these in their own analysis.\n(Not going to talk about things like measurment equivalence in internaitonal surveys although that is a thing!)\n\n2.4.2.1 Who is excluded?\nFor SCJS to be a measure of crime for all adults, not just all adults in private households, we need to make a key assumption that “the subset of the adult population not captured in the SCJS experience the same level of victimisation as adults in the household resident population”​\nBut this excludes people, students, people in prison, and those living in refuges. However, “Domestic abuse is the main cause of women’s homelessness in Scotland… All women living in Women’s Aid refuges have experienced domestic abuse and many will have experienced other forms of crime”\n(Scottish Women’s Aid 2021)\n“The self-completion questionnaire on partner abuse and the questionnaire on sexual violence are the last part of an already long interview. The 2019/2020 technical report notes that “ran out of time” accounts for 34.2% (the largest proportion) of reasons for not doing the selfcompletion part of the SCJS.”\nThis means that students are excluded from estimates of domestic abuse in Scotland.\nIf you want to fit a statistical model to SCJS to understand partner abuse you need to be aware of these issues and possible bias (in terms of non-representativeness that may arise)\nImportantly, this is not a sample size issue - if you had all the data on the people in the sampling frame then you still wouldn’t find out anything about students because they are excluded from the survey by design.\n\n\n\n2.4.3 Implications of the generative story for modelling\n\n2.4.3.1 Accounting for survey design in analysis\nCrime surveys usually come with sampling weights (see https://notstatschat.rbind.io/2020/08/04/weights-in-statistics/). This adjusts for the non-random selection of participants into the survey. It’s useful to think about the distinction between your survey and the population. If you want to calculate descriptive statistics from the survey that are accurate for the target population, you should use the weights. There are other occasions when you might want to know the unweighted/base sample size (e.g. to avoid presenting results that are based on a small number of responses). Different authorities have different perspectives on whether you should use sampling weights when fitting a statistical model. For example, Understanding Society say that you should definitely use sampling weights when analysing that dataset (https://www.understandingsociety.ac.uk/documentation/mainstage/user-guides/main-survey-user-guide/why-use-weights). Economists at the world bank say ‘yes when doing descriptive research and it depends when doing ’causal inference’” (https://www.nber.org/papers/w18859). As ever, the appropriate strategy will depend on the data you are working with and what question you are trying to answer. The best place to start is to consult the documentation for the survey you are using and see its description of the weights provided. For example, in the Scottish Crime and Justice survey they are different weights for individuals, households and incidents.\n\n\n2.4.3.2 What’s the population of interest?\nAgain, weights will only help adjust the data you see towards the target population in the survey design frame. Weighting cannot adjust for populations who are excluded from the survey by design.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#how-does-a-person-get-selected-for-the-scjs",
    "href": "types-of-data.html#how-does-a-person-get-selected-for-the-scjs",
    "title": "2  Types of criminological data",
    "section": "2.5 How does a person get selected for the SCJS?",
    "text": "2.5 How does a person get selected for the SCJS?\nRandom sample of 12,000ish postcodes in Scotland are contacted to take part​(for 2020/21 survey it was 12,681 addresses)\nFor those who agree, one adult (age 16 or over) in each household is randomly selected for interview​\nTherefore, by design no:​\n\nChildren​\nHomeless people​\nPeople living in communal establishments (e.g. students, people in prison)\n\nThere may also be limitations on who ends up in a survey dataset even if they are included in the design. With a focus on International Development, Carr-Hill says that “in practice, household surveys typically under-represent: those in fragile, disjointed households; slum populations and areas posing security risks.” (Carr-Hill 2013). The extent to which these factors may affect any particular data collection exercise may vary from having little to extreme impact (for example, research being conduct in a conflict zone). It is up to the researcher to determine the likely extent of factors such as these in their own analysis.\n(Not going to talk about things like measurment equivalence in internaitonal surveys although that is a thing!)\n\n2.5.0.1 Who is excluded?\nFor SCJS to be a measure of crime for all adults, not just all adults in private households, we need to make a key assumption that “the subset of the adult population not captured in the SCJS experience the same level of victimisation as adults in the household resident population”​\nBut this excludes people, students, people in prison, and those living in refuges. However, “Domestic abuse is the main cause of women’s homelessness in Scotland… All women living in Women’s Aid refuges have experienced domestic abuse and many will have experienced other forms of crime”\n(Scottish Women’s Aid 2021)\n“The self-completion questionnaire on partner abuse and the questionnaire on sexual violence are the last part of an already long interview. The 2019/2020 technical report notes that “ran out of time” accounts for 34.2% (the largest proportion) of reasons for not doing the selfcompletion part of the SCJS.”\nThis means that students are excluded from estimates of domestic abuse in Scotland.\nIf you want to fit a statistical model to SCJS to understand partner abuse you need to be aware of these issues and possible bias (in terms of non-representativeness that may arise)\nImportantly, this is not a sample size issue - if you had all the data on the people in the sampling frame then you still wouldn’t find out anything about students because they are excluded from the survey by design.\n\n\n2.5.1 Accounting for survey design in analysis\nCrime surveys usually come with sampling weights (see https://notstatschat.rbind.io/2020/08/04/weights-in-statistics/). This adjusts for the non-random selection of participants into the survey. It’s useful to think about the distinction between your survey and the population. If you want to calculate descriptive statistics from the survey that are accurate for the target population, you should use the weights. There are other occasions when you might want to know the unweighted/base sample size (e.g. to avoid presenting results that are based on a small number of responses). Different authorities have different perspectives on whether you should use sampling weights when fitting a statistical model. For example, Understanding Society say that you should definitely use sampling weights when analysing that dataset (https://www.understandingsociety.ac.uk/documentation/mainstage/user-guides/main-survey-user-guide/why-use-weights). Economists at the world bank say ‘yes when doing descriptive research and it depends when doing ’causal inference’” (https://www.nber.org/papers/w18859). As ever, the appropriate strategy will depend on the data you are working with and what question you are trying to answer. The best place to start is to consult the documentation for the survey you are using and see its description of the weights provided. For example, in the Scottish Crime and Justice survey they are different weights for individuals, households and incidents.\nAgain, weights will only help adjust the data you see towards the target population in the survey design frame. Weighting cannot adjust for populations who are excluded from the survey by design.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#who-is-excluded",
    "href": "types-of-data.html#who-is-excluded",
    "title": "3  Types of criminological data",
    "section": "3.10 Who is excluded?",
    "text": "3.10 Who is excluded?\nFor SCJS to be a measure of crime for all adults, not just all adults in private households, we need to make a key assumption that “the subset of the adult population not captured in the SCJS experience the same level of victimisation as adults in the household resident population”​\nBut this excludes people, students, people in prison, and those living in refuges​\n“Domestic abuse is the main cause of women’s homelessness in Scotland… All women living in Women’s Aid refuges have experienced domestic abuse and many will have experienced other forms of crime”\n\nFrom Handbook chapter - falling sample size, falling response rate and falling victimization all mean less ‘power’ in more recent SCJS sweeps\n\n“The reduction in survey response rates is a phenomenon that has been observed internationally (de Leeuw, Hox and Luiten, 2018), and there are particular concerns that it is the most marginalized in society (often the most prone to victimization) who are no longer responding to surveys (Savage and Burrows, 2009). Again, taking Scotland as an example, valid response rates to the SCJS fell from 71% in 2008/09 to 63% in 2019/20 (Saunders et al, 2021), with a urther reduction (following the Coronavirus pandemic) to just 47.3% in 2021/22 - the lowest response rate for any SCJS sweep since 2008/09 (Scottish Government 2023a). This issue has been compounded by reductions in the valid sample size for successive sweeps of the SCJS, which has reduced from 16,000 in 2008/09 to just 5,500 in the sweeps conducted since 2016/1714, largely in an effort to cut costs. Factoring in the large reduction in the prevalence of victimization (mentioned above), the stark reality is that the number of victims interviewed as part of the Scottish survey reduced from 2,786 in 2008/09 to just 639 in 2021/22. So, whilst the prevalence of crime fell by just over 50% (or in absolute terms, a fall of 10.4 percentage points), the number of survey respondents who had experienced at least one incident of crime has fallen by an astonishing 77%.”\nYou need to evaluate how useful a data source is in the context of your particular research question. e.g. you might be able to make an overall assessment of victimization for some social group but not look at a trend for that group, whilst you can look at trends for other groups. I guess this is curse of dimensionality. Or you might need a different model for some groups versus others/have to assume more.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#make-sure-the-data-is-right",
    "href": "types-of-data.html#make-sure-the-data-is-right",
    "title": "3  Types of criminological data",
    "section": "3.11 Make sure the data is right!!",
    "text": "3.11 Make sure the data is right!!\nhttps://x.com/jkangbrown/status/1790416534776562157",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "general-linear-model.html",
    "href": "general-linear-model.html",
    "title": "3  The general linear model",
    "section": "",
    "text": "3.1 Large worlds and small worlds\nRichard McElreath (McElreath 2020) talks about the ‘small world’ of the model and the ‘large world’ that we actually live in. Our spreadsheets and coefficients can only summarize the small world for us, and omit some of the complexity of the large world. This is fine if all we want to do is provide summaries of the the numbers in our spreadsheets. But as soon as we want to understand the large world we can run in to problems if all we focus on are the rows and columns in front of us. We often need to bring our understanding of the large world - for example, how an incident becomes a crime - to bear during statistical modelling. In this session we’ll overview two ways in which our understanding of the ‘large world’ might influence how we interpret our results from the ‘small world’: measurement error and selection effects.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The general linear model</span>"
    ]
  },
  {
    "objectID": "selection-measurement.html",
    "href": "selection-measurement.html",
    "title": "5  Selection effects, bias and so on",
    "section": "",
    "text": "5.1 Measurement error\nMeasurement error is just the gap between what we are conceptually interested in and the way that this concept is recorded in our spreadsheet.\nMeasurement error can impact an analysis in pretty much any conceiveable way, depending on the type, magnitude and source of measurement error - whether the error is in the outcome, or in a key independent variable, or in a control variable. The standard linear model which we have just been discussing assumes that all variables are measured perfectly (or in other words, with no error). It may bias your regression coefficients, meaning that your results are valid and in reality there is a stronger association between predictor and outcome that you have observed. It may not bias your regression coefficients at all but just impact the precision of your results. Other than in simple scenarios we may not know what impact it is having.\nIn practice we know criminological data are likely to be measured with some degree of error. For example, we know that police recorded crime data is not a perfect measure of the amount of crime ‘out there’ in society. As we have discussed already, not all crimes are reported to the police, not all incidents which are reported are recorded as crimes and so on.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Selection effects, bias and so on</span>"
    ]
  },
  {
    "objectID": "selection-measurement.html#solutions",
    "href": "selection-measurement.html#solutions",
    "title": "5  Selection effects, bias and so on",
    "section": "5.3 Solutions?",
    "text": "5.3 Solutions?\nKnox et al. (2020) suggest some technical fixes, but emphasise that - if we are interested in using statistical models to identify causal relationships there is no general solution that can guarantee that coefficients in a regression model will have valid causal interpretations based on administrative data derived from police records. The key thing is thinking through the process by which the dataset was constructed, and conveying this to your reader.\nmaybe get the students to play about with the data in the dataverse?https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/KFQOCV\n\n5.3.1 Confounding\nConfounding describes a situation where there’s something that we know affects the outcome we’re interested in and/or our independent variables, but we don’t have a measure for this. In criminology, we might have measures of police stops but not offending (.e.g from self-reports). Offending is likely to be a big - but not the only driver - of whether a person has contact with the police.\n\nbecause we do not see U, we must impute its values using probabilities (bets) about the values of U given what we do see (again, X and Y ).\n\nThe tipr approach is to unmeasured confounding - not just that we have a variable measured inaccurately, but that there is a key variable we haven’t measured\nneed some criminological examples here",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Selection effects, bias and so on</span>"
    ]
  },
  {
    "objectID": "selection-measurement.html#probabilistic-bias-analysis",
    "href": "selection-measurement.html#probabilistic-bias-analysis",
    "title": "4  Selection effects, bias and so on",
    "section": "4.4 Probabilistic Bias Analysis",
    "text": "4.4 Probabilistic Bias Analysis\nWhat Knox et al. suggest is part of a set of approaches called Probabilistic Bias Analysis. This includes things like understanding selection bias, unmeasured confounding and misclassification.\nThere are whole books written on this topic! So no general solutions here.\n\n4.4.1 Selection bias\n(Greenland 2014)\nWe only see people in our study if they meet some criterion (in other words, where S = 1), but we want to see everybody (i.e. people for whom S = 0)\n“But because we see only the relation of X to Y conditional on selection (S D 1), we must impute the unconditional relation of X to Y using probabilities of selection given what we do see (X and Y given S D 1).” In the Knox and colleagues example, this would require knowing the numbers of people who were observed by police but not stopped, in order to calculate the probabilities of selection into the stop dataset. However, we don’t know this - and it is hard to imagine a scenario where an analyst of an police administrative dataset would know this.\nEven if we do know this for our particular dataset, there is no guarantee that selection into the data would hold in every case that we might want to generalize our results to. As such we’d need to consider how differences between the study populations may have affected response and selection (e.g. would selection probabilities from a US study map onto a study in Manchester? How about one in Glasgow?)\n\n\n4.4.2 Confounding\nConfounding describes a situation where there’s something that we know affects the outcome we’re interested in and/or our independent variables, but we don’t have a measure for this. In criminology, we might have measures of police stops but not offending (.e.g from self-reports). Offending is likely to be a big - but not the only driver - of whether a person has contact with the police.\n\nbecause we do not see U, we must impute its values using probabilities (bets) about the values of U given what we do see (again, X and Y ).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selection effects, bias and so on</span>"
    ]
  },
  {
    "objectID": "selection-measurement.html#in-general",
    "href": "selection-measurement.html#in-general",
    "title": "5  Selection effects, bias and so on",
    "section": "5.4 In general",
    "text": "5.4 In general\nNeed to make assumptions about the magnitude of the bias to implement any of the technical fixes. Fine. But where does this information come from?\n“The preceding approach assumes that U is a known confounder (e.g., a smoking indicator) that was unmeasured in the study in question but has been previously identified and subject to study in relation to disease if not exposure. If instead U represents an unspecified, unknown confounder, then the entire sensitivity exercise will remain far more speculative. Nonetheless, decomposition of the bias factor can still be successful in demonstrating that only implausibly strong confounder or selection effects can account for a strong observed association. Cornfield et al. (1959) is considered a landmark study in which such an approach was used to examine claims that the smoking-lung cancer relation might be attributable to confounding”\n\nso this is based on the idea tat we can identify an “implausibly strong” confounder, which is reasonable.\nOne approach is to pick a bunch of possible bias parameters and test to see if results are robust to all of them.\n\n“Despite these considerations, there is no basis for mandating a bias analysis of every study or even most studies. For example, bias analysis is superfluous when conventional intervals show that no useful conclusion could be drawn from the study even if it were perfect apart from random error. More generally, rather than providing a bias analysis, a study may provide greater service by refraining from inference; instead it can focus on carefully reporting its design, conduct, and data in great detail to facilitate pooling and meta-analysis (Greenland et al. 2004). Inferences are best based on a more complete account of evidence than can be provided in a single study report, and thus the effort of bias analysis is more justifiable in research synthesis (Turner et al. 2009; Welton et al. 2009). Even there, bias analysis becomes essential only when doing risk assessment or when authors claim to offer near-definitive conclusions.” (Greenland 2014, p703)\n… so you only need to bother with this stuff if you ‘claim to offer near-definitive conclusions’. Is your study likely to contribute to a meta analysis? Or in other words, when you are moving between the small world and the large world.\nMeans humility when making policy recommendations!!\nIs the small world enough? How do we talk about this? e.g. if all we’ve done is analysed convictions data do we talk about offending, or just conviction?\n\n\n\n\nBlackwell, Matthew, James Honaker, and Gary King. 2017. “A Unified Approach to Measurement Error and Missing Data: Overview and Applications.” Sociological Methods & Research 46 (3): 303–41. https://doi.org/10.1177/0049124115585360.\n\n\nBushway, Shawn, Brian D. Johnson, and Lee Ann Slocum. 2007. “Is the Magic Still There? The Use of the Heckman Two-Step Correction for Selection Bias in Criminology.” Journal of Quantitative Criminology 23 (2): 151–78. https://doi.org/10.1007/s10940-007-9024-4.\n\n\nGaebler, Johann, William Cai, Guillaume Basse, Ravi Shroff, Sharad Goel, and Jennifer Hill. 2022. “A Causal Framework for Observational Studies of Discrimination.” Statistics and Public Policy 9 (1): 26–48. https://doi.org/10.1080/2330443X.2021.2024778.\n\n\nGreenland, Sander. 2014. “Sensitivity Analysis and Bias Analysis.” In Handbook of Epidemiology, edited by Wolfgang Ahrens and Iris Pigeot, 685–706. New York, NY: Springer. https://doi.org/10.1007/978-0-387-09834-0_60.\n\n\nPina-Sánchez, Jose, and John Paul Gosling. 2020. “Tackling Selection Bias in Sentencing Data Analysis: A New Approach Based on a Scale of Severity.” Quality & Quantity 54 (3): 1047–73. https://doi.org/10.1007/s11135-020-00973-z.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Selection effects, bias and so on</span>"
    ]
  },
  {
    "objectID": "intro.html#using-models-to-describe-quantities-of-interest",
    "href": "intro.html#using-models-to-describe-quantities-of-interest",
    "title": "1  Introduction",
    "section": "1.4 Using models to describe quantities of interest",
    "text": "1.4 Using models to describe quantities of interest\n\nGary King and general principle\nsecondary motivation of what is your estimand?\ngeneral principle of adjusted predictive comparisons (and also g-estimation)\nspecific example of victimization divides as a DQI",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "general-linear-model.html#assumptions-and-p-values",
    "href": "general-linear-model.html#assumptions-and-p-values",
    "title": "3  The general linear model",
    "section": "3.5 Assumptions and p-values",
    "text": "3.5 Assumptions and p-values\nhttps://bristoluniversitypressdigital.com/edcollchap/book/9781529232073/ch014.xml\nFocus on effect size measures instead?\nThink about populations hard (https://benmatthewsed.github.io/what_to_do_odds_ratios/what_to_do_odds_ratios.html#/title-slide)\n\n3.5.1 An example of thinking about populations and generalization\nThis question came from the Policing the Pandemic in Scotland project with excellent colleagues Dr Vicky Gorton and Prof Susan McVie\nWe linked data on all (well, most) fines received for breaching the Covid regulations in Scotland between 27 March 2020 to 31 May 2021 with information on recipients’ health (service use) and (some) social circumstances (I’m not going to go into detail about this)\nWe also have the same information on a comparison group of matched controls (matched by age, sex, Local Authority and SIMD decile)\nWe want to know if people with more ‘vulnerability’ (read - health service use) are more likely than others to have received a Covid fine (FPN)\nHaving done all this, I actually don’t think we’ll use this in our paper. Thinking hard about the population that we’re interested in made me wonder…\n… and what’s wrong with an odds ratio of 35 anyway?\nThis is an accurate description of our dataset!\nIf the problem is that we don’t think a result this extreme would generalize to another ‘sample’ from the sample population - with close to every person who received an FPN do we even have any issues of generalizability (we have basically 100% of the relevant people, minus matching error)?\nInstead of generalizability, I think we have either a massive issue with transportability/external validity (Degtiar and Rose 2023), or we have no issue at all\nIt seems nonsensical to suggest that these results would apply to another country during Covid or another pandemic (countries were very different in their responses)\nThe results for Lockdown One in Scotland don’t even generalize to Lockdown Two - we show that in our analysis!\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and STAN. CRC Press.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The general linear model</span>"
    ]
  },
  {
    "objectID": "selection-measurement.html#draw-from-pina-sanchez",
    "href": "selection-measurement.html#draw-from-pina-sanchez",
    "title": "Selection effects, bias and so on",
    "section": "Draw from Pina sanchez",
    "text": "Draw from Pina sanchez\nhttps://josepinasanchez.uk/wp-content/uploads/2021/12/rmef_measurement-error_b.pdf\nfrom https://josepinasanchez.uk/short-courses/",
    "crumbs": [
      "Selection effects, bias and so on"
    ]
  },
  {
    "objectID": "selection-measurement.html#measurement-error",
    "href": "selection-measurement.html#measurement-error",
    "title": "5  Selection effects, bias and so on",
    "section": "",
    "text": "5.1.0.1 Example One: Measurement error in police recorded crime data\n\nFrom our discussion in Session One, we know that crime data recorded by the police are not a complete record of all crimes experienced in society in a given period - only crimes which are reported and recorded make it into recorded crime data.\nSo if we are interested in, for example, how many crimes there were in Scotland in 2023, the number of crimes recorded by police is likely to be an under count.\nThe many years of work comparing crimes recorded to the police with victimization surveys - the ‘dark figure of crime’ - attests to this.\n\n\n\n5.1.0.2 Example Two: Measurement error in victimizaton survey data\n\nHistorically, national victimization surveys (such as the SCJS and CSEW) capped the number of victim forms that victims could complete. In 2019, ONS said that “Since the survey began in 1981, “repeat” incidents have been limited to a total of 5. Historically, including a maximum of 5 repeat incidents for any individual victim had proven to be an effective way of reducing the effects of sample variability from year to year. This approach enabled the publication of incident rates that were not subject to large fluctuation between survey years. This approach yields a more reliable picture of changes in victimisations over time once high order repeat victimisations were treated in this way.” (https://doc.ukdataservice.ac.uk/doc/7280/mrdoc/pdf/7280_csew_improving_victimisation_estimates_2019.pdf)\nHowever, it also means that people who experienced more than five incidents of a particular ‘series’ crime type did not have their data accurately recorded\nThis was particularly important for women’s reporting of violent victimization (Walby et al. 2015) - women who experienced domestic violence may well report more than five repeat incidents of victimization in a given year. A second measurement error issue came from the ‘97 code’ - the option to report the number of incidents experienced as ‘96/too many to count’. Instead, based on the domestic violence literature Walby and colleagues propose using an estimate of 60 incidents for those who report the 97 code.\nSometimes it’s possible to use uncapped data\n\n\n\n5.1.1 What to do about it?\nWhat’s more is that it’s not entirely clear what to do about it.\nOne way to approach this, if we know or can reasonably approximate the model for the measurement error then we can use Bayesian methods to jointly estimate a model for our observations and the measurement error. This is easier said than done! Bayesian methods are extremely flexible and allow the researcher to model to specify a model for the measurement error which is estimated jointly with the model for their outcome. This relies on knowing what the right model for the measurement error should be. It also relies on fitting a Bayesian model to your data which comes with its own set of challenges.\nPina-Sanchez has written about measurement error in crime.\nOne approach is to use Bayesian methods.\nPina Sanchez gave a workshop on Bayesian adjustments for measurement error, and you can find the materials here: https://josepinasanchez.uk/short-courses/\nhttps://josepinasanchez.uk/wp-content/uploads/2021/12/rmef_measurement-error_b.pdf\nfrom https://josepinasanchez.uk/short-courses/\n\n\n5.1.2 SIMEX\nA less involved option involves assessment measurement error through simulation. The process here is to fit the model to the data as observed and try to figure out what the coefficients would be if there was no measurement error in the data. The simex R package lets you simulate new versions of your dataset with more and more measurement error. By looking to see how your coefficients change after re-fitting your model with increasing measurement error you can project backwards to what the coefficients would be with zero measurement error. Neat!\nHowever, SIMEX works best when there is only one variable with measurement error in the analysis, and can be more difficult to compute when there are multiple variables with measurement error (Blackwell, Honaker, and King 2017)\n\n\n5.1.3 rcme\nPina-Sanchez and colleagues have written an R package that can conduct sensitivity analysis for some types of measurement error common to working with police recorded crime.\n\nWork through their example here? https://osf.io/preprints/socarxiv/sbc8w\n\nOpen questions - what about survey data? Models other than linear models?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Selection effects, bias and so on</span>"
    ]
  },
  {
    "objectID": "simulation.html",
    "href": "simulation.html",
    "title": "4  Simulation",
    "section": "",
    "text": "4.1 Add clarify example here\nIn the example above we performed the simulation from each models’ variance-covariance matrix ourselves. Whilst it’s good to know how this works, in practice there are R packages which can do this for us. One good option is clarify.\nHere we reproduce our results using clarify. Instead of fitting a model to each year as above, clarify expects us to give it a single model object, so we re-express the two separate models (one for each year) as a single model, now including year as an interaction term with sex.\n# using clarify -----------------------------------------------------------\n\nlibrary(clarify)\n\n\nmod1 &lt;- glm(cbind(vict, n - vict) ~ fct_rev(sex) * year,\n                 family = \"binomial\",\n                 data = dat)\n\ns &lt;- sim(mod1,\n         n = n_sims)\n\n\nsim_fun2 &lt;- function(coefs) {\n  men_2015 &lt;- unname(coefs[\"fct_rev(sex)men\"])\n  men_interact &lt;- unname(coefs[\"fct_rev(sex)men:year2020\"])\n  \n  men_2020 &lt;- men_2015 + men_interact\n  \n  or_2015 &lt;- exp(men_2015)\n  or_2020 &lt;- exp(men_2020)\n  \n  victim_divide(or_2015, or_2020)\n  \n}\n\n\nest2 &lt;- sim_apply(s, \n                  FUN = sim_fun2)\n\ntibble(x = as.vector(est2)) |&gt; \n  reframe(vds = quantile(x, c(0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.975, 0.99)),\n          vals = c(0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.975, 0.99))\n\n# A tibble: 11 × 2\n       vds  vals\n     &lt;dbl&gt; &lt;dbl&gt;\n 1 -1.12   0.01 \n 2 -1.02   0.025\n 3 -0.948  0.05 \n 4 -0.860  0.1  \n 5 -0.710  0.25 \n 6 -0.524  0.5  \n 7 -0.296  0.75 \n 8 -0.0193 0.9  \n 9  0.210  0.95 \n10  0.469  0.975\n11  0.911  0.99\nHere we can see that the results are basically the same.\nWhy clarify:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "general-linear-model.html#a-note-on-bespoke-models",
    "href": "general-linear-model.html#a-note-on-bespoke-models",
    "title": "3  The general linear model",
    "section": "3.6 A note on bespoke models",
    "text": "3.6 A note on bespoke models\nI am extremely partial to bespoke models. If you have the time I would recommend reading and watching all the Statistical Rethinking lectures - this gives an introduction into building your own models tailored to your specific data and problems. But that will take weeks and weeks and we are only here until five.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The general linear model</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#geography",
    "href": "types-of-data.html#geography",
    "title": "2  Types of criminological data",
    "section": "2.2 Geography",
    "text": "2.2 Geography\nMostly scope is national, but not always​\nSome local surveys​(suchas MOPAC/Islington Crime Survey)\nCan get data on trends for [individual police forces in the UK] (https://data.police.uk/data/), or [victimization survey data aggreted to police division level within Scotland] (https://scotland.shinyapps.io/sg-scottish-crime-justice-survey/)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "ethics.html",
    "href": "ethics.html",
    "title": "6  Ethics",
    "section": "",
    "text": "6.1 Reproducible research practices?\nMake sure the data is right!!\nhttps://github.com/jkangbrown/when_police_replication",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ethics</span>"
    ]
  },
  {
    "objectID": "ethics.html#framing",
    "href": "ethics.html#framing",
    "title": "6  Ethics",
    "section": "6.2 Framing",
    "text": "6.2 Framing\nMore conceptually, it’s important to think about how we frame the results of any analysis.\nThree visualizations from Data Feminism\n\nlanguage use\nproviding necessary context?\ndeficit narrative\nthe description of your charts is theoretically informed",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ethics</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#generative-stories-for-common-types-of-crime-data",
    "href": "types-of-data.html#generative-stories-for-common-types-of-crime-data",
    "title": "2  Types of criminological data",
    "section": "2.2 Generative stories for common types of crime data",
    "text": "2.2 Generative stories for common types of crime data\n\n2.2.1 How does an event become a crime statistic?\nIn Scotland there is a very nice discussion of how police recorded crime statistics are put together in the Scottish Government User Guide to Recorded Crime. We can think of this process as involving four main components:\n - Reporting: Most of the time incidents come to the attention of the police after a member of the public reports it. However, we know that not all incidents are reported to the police, and not all people are equally likely to report incidents if they are victims (Fohring 2014) - Fact-checking/investigation: Police need to collect initial information about an incident to establish whether a crime has occurred - Discretion/judgement: Even if the police believe a crime has occurred, not all incidents are followed up, for example if a victim chooses not to prosecute or provide details of the perpetrator (Aplin 2019). Maybe add discussion of (Hope 2023) here? - Applying crime counting rules: This might affect the type of crime an incident is recorded as, including whether it is classed as a hate crime. The current Scottish Crime Recording Standard is 550 pages long (!). I have not read it.\n\n\n2.2.2 Answering our key questions\n\n\n2.2.3 Implications of the generative story\n\n2.2.3.1 System or heaviour?\nBecause of all these processes there has long been a question about the extent to which official crime statistics reflect ‘behavioural’ trends in crime, or just the actions of the justice system (Kitsuse and Cicourel 1963; Hope 2023), and how you see this may depend on your theoretical persuasion (Simes, Beck, and Eason 2023). We’ll discuss some practical impacts this may have on analysis later in the workshop.\n\n\n2.2.3.2 Undercounting and the dark-figure\n\n\n2.2.3.3 Population or super-population?\n(Verlaan and Langton 2024) outline two possible approaches to conceptualizing police recorded crime data: a population or superpopulation approach.\nIn the population approach the data you observe for a particular time and place (e.g. Scotland in 2023) are all the data you could ever observe - you don’t need to fit statistical models to generalize from the data you observe to a wider population because there is no wider population. [^2] You have the data you have, and that’s that.\n[^2:] You might want to fit models for other reasons though.\nIn the superpopulation approach you are interesting in thinking about other ways the data you have may have arisen. Verlan and Langton (2024) give examples where you may think that data on crimes recorded by police in cities in Texas from 2023 were data drawn from the population of cities in the whole USA, or the whole of the USA, or the whole planet. Alternatively, data from cities in Texas from 2023 may be seen as a sample from cities in Texas from 2023 and 2024, or 2023-2030 and so on. Gelman (2011) takes this approach using an example from political science - you may have data on all seats in a lesislature but want to predict what will happen to those same seats in future elections under “hypothetical alternative conditions”. Applying the same logic, statistical models could be used with police recorded crime data to ask ‘counterfactual’ questions about what crime rates in Dallas may have been if the poverty rate fell by 5%.\nVerlan and Langton list some possible problems using inferential statistcs/statistical models using administrative data.\n\nIt wrongly leads people to assume that their results are generalizable. This is often not done explicitly but implicitly (for example suggesting that results may apply in other jurisdictions)\nIt can lead people to undervalue actual observed differences in their data. For example, researchers may deny that an association between two variables exists in their dataset if it is not statistically significant",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "general-linear-model.html#count-data",
    "href": "general-linear-model.html#count-data",
    "title": "3  The general linear model",
    "section": "3.3 Count data",
    "text": "3.3 Count data\nCount data are counts of things. That’s it! This means that they non-negative whole numbers. Count data are common in criminology when it comes to modelling crime - e.g. the number of crimes reported to the police, or the number of victimization incidents experienced by victims.\nWhilst we may see crime data be re-expressed as rates per 1,000 population, before this they are counts.\nThe foundational model for count data is the Poisson model:\n\\[\n\\begin{align*}\ny_i \\sim & {Poisson} (\\lambda) \\\\\n{log(\\lambda)} & = \\alpha + \\beta (x_i),\n\\end{align*}\n\\]\nNow there is only one parameter (lambda; \\(\\lambda\\)) that we are modelling, unlike with linear regression. This means that in Poisson models the mean and the variance are assumed to be the same (or put another way, that they are both direct functions of \\(\\lambda\\)).\nThe coefficients from Poisson models (which range from \\(-\\infty\\) to \\(\\infty\\)) are converted to be predicted counts that are non-negative integers via the \\(\\log\\) link function.\nGraph of log here?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The general linear model</span>"
    ]
  },
  {
    "objectID": "general-linear-model.html#why-not-just-lm",
    "href": "general-linear-model.html#why-not-just-lm",
    "title": "3  The general linear model",
    "section": "3.4 why not just lm?",
    "text": "3.4 why not just lm?\n\nYou can get negative predictions\nLM assumes constant variance - we probably want more variance for larger counts\n\n\n3.4.1 Specific problems with GLMs\n\n3.4.1.1 over-dispersion\n\npoisson assumes mean and variance are the same (only one term in the model)\nso what? mostly under-estimates the standard error\np-values are too optimistic\nyou need to think about why your data are over-dispersed\nif all you care about is your standard errors you can use quasi-poisson (same point estimates as poisson but with ‘empirical’ SEs - similar to using robust standard errors)\nFrancis et al. use this approach to modelling counts of victimization\nYou can also use negative binomial\n\n\n\n3.4.1.2 zero-inflation\ntake from Hilbe (distinct zeros? ZIP; generic solution; NB?)\n\nZIP can have different predictors for zeros than count part\nyou can also have different predictors for dispersion and rate parameter in NB if you want\n\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and STAN. CRC Press.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The general linear model</span>"
    ]
  },
  {
    "objectID": "general-linear-model.html#logistic-regression",
    "href": "general-linear-model.html#logistic-regression",
    "title": "3  The general linear model",
    "section": "3.3 Logistic regression",
    "text": "3.3 Logistic regression\nFor logistic regression we have:\n\\[\n\\begin{align*}\ny_i \\sim & {Binomial} (n, p_i) \\\\\n{logit(p_i)} & = \\alpha + \\beta (x_i),\n\\end{align*}\n\\] for logistic regression, \\(n\\) = 1, and we are just interested in modelling \\(p_i\\).\nThese kinds of models are very common in the social sciences, including in criminology. We might want to model whether someone is a victim of crime or not, or whether the person has been convicted of a crime in a given year, or whether they are confident in the police or not… and so on and so on. The nice thing about this model formulation is that the \\({logit}\\) link function makes sure that all the probabilities the model estimates are between 0 and 1. Strictly speaking we don’t need to do this (see the linear probability model), but it’s nice to avoid results that obviously don’t make sense, like negative probabilities and such.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The general linear model</span>"
    ]
  },
  {
    "objectID": "general-linear-model.html#intro-to-glm",
    "href": "general-linear-model.html#intro-to-glm",
    "title": "3  The general linear model",
    "section": "3.2 Intro to GLM",
    "text": "3.2 Intro to GLM\nThings we don’t cover: - Won’t include: mixed/multilevel/hierarchical/etc - Additive models (GAMs) - ‘bespoke’ models\nRecommended watching: https://www.youtube.com/watch?v=qbxNf4iqJPo&t=1215s\nIntroduction to LM\n\nStochastic (or random) component\nSystematic component\nLink function\n\n(I adapted this notation from Solomon Kurz https://bookdown.org/content/4857/god-spiked-the-integers.html#poisson-regression)\n\\[\n\\begin{align*}\ny_i \\sim & {Distribution} (\\theta_i, \\phi) \\\\\n{f(\\theta_i)} & = \\alpha + \\beta (x_i - \\bar x),\n\\end{align*}\n\\]\nwhere \\(\\theta_i\\) is the parameter of interest (e.g., the probability of 1 in a Binomial distribution) and \\(\\phi\\) is a placeholder for any other parameters necessary for the likelihood but not typically of primary substantive interest (e.g., \\(\\sigma\\) in conventional Gaussian models). The \\(f(\\cdot)\\) portion is the link function.\nFor the linear model, we have:\n\\[\n\\begin{align*}\ny_i \\sim & {Normal} (\\theta_i, \\sigma) \\\\\n{Identity(\\theta_i)} & = \\alpha + \\beta (x_i - \\bar x),\n\\end{align*}\n\\]\n\nan example here?\n\nOne key feature of a GLM is that you can get predictions for your outcome by adding up the coefficients for each element of your systematic component, and then applying the appropriate transformation through the link function.\n\n3.2.1 Logistic regression\nFor logistic regression we have:\n\\[\n\\begin{align*}\ny_i \\sim & {Binomial} (n, p_i) \\\\\n{logit(p_i)} & = \\alpha + \\beta (x_i),\n\\end{align*}\n\\] for logistic regression, \\(n\\) = 1, and we are just interested in modelling \\(p_i\\).\nThese kinds of models are very common in the social sciences, including in criminology. We might want to model whether someone is a victim of crime or not, or whether the person has been convicted of a crime in a given year, or whether they are confident in the police or not… and so on and so on. The nice thing about this model formulation is that the \\({logit}\\) link function makes sure that all the probabilities the model estimates are between 0 and 1. Strictly speaking we don’t need to do this (see the linear probability model), but it’s nice to avoid results that obviously don’t make sense, like negative probabilities and such.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The general linear model</span>"
    ]
  },
  {
    "objectID": "selection-measurement.html#selection-effects",
    "href": "selection-measurement.html#selection-effects",
    "title": "5  Selection effects, bias and so on",
    "section": "5.2 Selection effects",
    "text": "5.2 Selection effects\nSelection bias arises when there are people who we would have liked to observe in our study but we don’t observe them, and this lack of observation is related to their characteristics. Put another way, we can think of selection bias as affecting the rows of our dataset - there are some rows that are missing that we would like to see.\n(Greenland 2014)\nWe only see people in our study if they meet some criterion (in other words, where S = 1), but we want to see everybody (i.e. people for whom S = 0)\n“But because we see only the relation of X to Y conditional on selection (S D 1), we must impute the unconditional relation of X to Y using probabilities of selection given what we do see (X and Y given S D 1).”\nBushway (2007) gives an example from sentencing research: say we want to investigate racial discrimination in sentencing. A common approach has been to focus on whether people from different ethnic backgrounds receive different lengths of prison sentence, after statistically adjusting for other factors such as the offence type, age at time of offence and so on (Pina-Sánchez and Gosling 2020). However this creates a selection bias problem - not all convictions lead to custodial sentences, and so focusing only on custodial sentences means that the analyst is focusing on discrimination “conditional on being selected into the incarcerated population” (Bushway, Johnson, and Slocum 2007). Any results derived would then not relate to all convicted people.\nAdd more from (https://www-jstor-org.ezproxy-s2.stir.ac.uk/stable/2095230?seq=8)?\nIn the Knox and colleagues example, this would require knowing the numbers of people who were observed by police but not stopped, in order to calculate the probabilities of selection into the stop dataset. However, we don’t know this - and it is hard to imagine a scenario where an analyst of an police administrative dataset would know this.\nEven if we do know this for our particular dataset, there is no guarantee that selection into the data would hold in every case that we might want to generalize our results to. As such we’d need to consider how differences between the study populations may have affected response and selection (e.g. would selection probabilities from a US study map onto a study in Manchester? How about one in Glasgow?)\nSome links on where to read more about causal inference? Maybe here\nImagine that we want to know whether police are racially biased in how they treat members of the public. One way to assess this is by using data from the police about the outcomes of their interactions with the public.\nFor example, we might want to know if people from minority ethnic backgrounds more likely to be arrested after a stop than people from white backgrounds (Knox et al)\nPolice collect data on stops - why not just run a regression on these data to see if people from minority ethnic backgrounds are more likely to be stopped?\nThe problem is we can’t just rely on data about police stops - “if police racially discriminate when choosing whom to investigate, analyses using administrative records to estimate racial discrimination in police behavior are statistically biased, and many quantities of interest are unidentified—even among investigated individuals—absent strong and untestable assumptions.”\nWe’re going to hear a lot about ‘strong and untestable assumptions’.\n“when there is any racial discrimination in the decision to detain civilians—a decision that determines which encounters appear in police administrative data at all—then estimates of the effect of civilian race on subsequent police behavior are biased absent additional data and/or strong and untestable assumptions.”\n[INSERT FIGURE 2 FROM KNOX]\n\n\n\nKnox et al (2020) FIGURE 2. Principal Strata and Observed Police–Civilian Encounters. Notes: The figure displays the four principal strata that comprise police–civilian encounters based on how the mediator M (whether a civilian is stopped by police) responds to treatment D (whether the civilian is a racial minority). Minorities in the “always stop” and anti-minority racial stop strata, highlighted in red, are stopped by police and, thus, appear in police administrative data. Likewise, white civilians in the “always-stop” and anti-white racial stop strata, highlighted in blue, appear in police data. “Never stop” encounters are unobserved. Because white and nonwhite encounters are drawn from different principal strata, the two groups are incomparable and estimates of causal quantities using observed encounters will be statistically biased absent additional assumptions.\n\n\nIf you only analyse data that are the result of police stops then your results will be biased. To analyse data on police stops to estimate racial bias, you also need to know the total number of encounters (for each ethnic group) – that is, including encounters that did not lead to a stop.\nOthers (Gaebler et al. 2022)suggest that maybe you can identify some aspects of discrimination in administrative data. This would be discrimination at some point in the process, not total discrimination. It’s really important to be clear about what it is you want to know – do you care about total discrimination, or discrimination in a particular part of the process (e.g. court sentencing and not policing?).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Selection effects, bias and so on</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#footnotes",
    "href": "types-of-data.html#footnotes",
    "title": "2  Types of criminological data",
    "section": "",
    "text": "‘Generative modelling’ is - depressingly - a term that means different things to different audiences (Sankaran and Holmes 2023). Michael Betancourt talks about ‘narratively generative’ models (betancourtWhatProbabilisticStory?), which is a terminology I quite like - we can tell a story about how the data came to be and this can influence the model/s we fit.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#section",
    "href": "types-of-data.html#section",
    "title": "2  Types of criminological data",
    "section": "2.6 ",
    "text": "2.6 \n\n2.6.1 CVI data?\nhttps://www.scotland.police.uk/about-us/covid-19-police-scotland-response/enforcement-and-response-data/\n“In response to the introduction of The Health Protection (Coronavirus) (Restrictions) (Scotland) Regulations 2020 and Coronavirus Act 2020, Police Scotland developed a ‘Coronavirus Interventions’ (CVI) recording system. This system allowed Police Scotland to begin gathering data in relation to the public co-operation levels with the new legislation. This system relies on Police Officers manually updating the system with the co-operation level when they encounter an individual in contravention of the new legislation. Due to the manual input required to form this data set, the contents of this slide are indicative only. Actual figures will differ from those recorded on Crime Systems (please see further slide), may be subject to change, and cannot be considered Official Police Statistics. They do provide an indication of the public co-operation levels across Scotland.”\n“Notes on the CVI System The second data source was the Coronavirus Intervention (CVI) system, introduced by Police Scotland on 6 April 2020 in response to the introduction of the Coronavirus Act 2020 and associated Health Protection Regulations in Scotland.52 Data from the CVI were published throughout the pandemic on a weekly basis by Police Scotland until 17 November 2021. The main purpose of this system was to gather data on levels of public co-operation with the new Regulations, based on police officer interventions. The CVI system relies on manual updates from police officers about any interventions they have had with members of the public in respect of the legislation. It is not compulsory and, as a result, does not provide a comprehensive estimate of the total number of policing encounters. Nevertheless, it measures all policing-related activity (not just use of enforcement) and so provides a useful indicator of the relative use of different types of police activity in the context of the ‘Four Es strategy’, which was widely adopted by police forces across the UK in the context of the pandemic.53 To our knowledge, the CVI System is the only database of its kind to be used to measure the overall use of extended policing powers across the UK police forces from the start of the pandemic. Therefore, it provides an extremely useful source of complementary information to the FPN data. Comparison between FPN tickets and the CVI system Figure 22 shows a comparison of the number of tickets issued and the number recorded on the CVI as a seven-day rolling average between 27 March 2020 and 31 May 2021. The dark line shows the average number of FPNs issued, and the light line shows the average number recorded on Police Scotland’s CVI system. Both trend lines show four ‘phases’ of policing activity in relation to FPNs which are broadly reflective of the tightening and easing of restrictions in Scotland. The total number of FPN tickets actually issued (n = 20,410) was 20.9% higher than the number recorded on Police Scotland’s Coronavirus Intervention (CVI) system over the same period (n = 16,876)” https://www.law.ed.ac.uk/sites/default/files/2022-08/FPN%204th%20report%20-%20FINAL.pdf\n\n\n\n\nAplin, Rachael. 2019. “The Grey Figure of Crime: If It Isn’t Crimed, It Hasn’t Happened.” In Policing UK Honour-Based Abuse Crime, edited by Rachael Aplin, 101–52. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-030-18430-8_4.\n\n\nAtak, Kıvanç. 2020. “Beyond the Western Crime Drop: Violence, Property Offences, and the State in Turkey 1990–2016.” International Journal of Law, Crime and Justice 60 (March): 100373. https://doi.org/10.1016/j.ijlcj.2019.100373.\n\n\nBuil-Gil, David, Ian Brunton-Smith, Jose Pina-Sánchez, and Alexandru Cernat. 2022. “Comparing Measurements of Violent Crime in Local Communities: A Case Study in Islington, London.” Police Practice and Research 23 (4): 489–506. https://doi.org/10.1080/15614263.2022.2047047.\n\n\nCarr-Hill, Roy. 2013. “Missing Millions and Measuring Development Progress.” World Development 46 (June): 30–44. https://doi.org/10.1016/j.worlddev.2012.12.017.\n\n\nFohring, Stephanie. 2014. “Putting a Face on the Dark Figure: Describing Victims Who Don’t Report Crime.” Temida 17 (4): 3–18.\n\n\nHope, Tim. 2023. “The Effect of ‘Third Party’ Pressure on Police Crime Recording Practice.” CrimRxiv.\n\n\nKitsuse, John I., and Aaron V. Cicourel. 1963. “A Note on the Uses of Official Statistics.” Social Problems 11 (2): 131–39. https://doi.org/10.2307/799220.\n\n\nPina-Sánchez, Jose, Sara Geneletti, Ana Veiga, Ana Morales, and Eoin Guilfoyle. 2022. “Ethnic Disparities in Sentencing: Warranted or Unwarranted?” OSF. https://doi.org/10.31235/osf.io/k8bsg.\n\n\nSankaran, Kris, and Susan P. Holmes. 2023. “Generative Models: An Interdisciplinary Perspective.” Annual Review of Statistics and Its Application 10 (Volume 10, 2023): 325–52. https://doi.org/10.1146/annurev-statistics-033121-110134.\n\n\nScottish Women’s Aid. 2021. “Response to the Consultation on the Scottish Crime and Justice Survey (SCJS), December 2021.” https://womensaid.scot/wp-content/uploads/2022/04/SWA-response-to-Scottish-Crime-and-Justice-Survey-consultation.pdf.\n\n\nSimes, Jessica T., Brenden Beck, and John M. Eason. 2023. “Policing, Punishment, and Place: Spatial-Contextual Analyses of the Criminal Legal System.” Annual Review of Sociology 49 (1): 221–40. https://doi.org/10.1146/annurev-soc-031021-035328.\n\n\nVerlaan, Tim, and Samuel Langton. 2024. “On the Use of Inferential Statistics on Administrative Police Data.” In The Crime Data Handbook, 197–210. Bristol University Press.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "selection-measurement.html#quantitative-bias-analysis",
    "href": "selection-measurement.html#quantitative-bias-analysis",
    "title": "4  Selection effects, bias and so on",
    "section": "4.4 Quantitative Bias Analysis",
    "text": "4.4 Quantitative Bias Analysis\nWhat Knox et al. suggest is part of a set of approaches called Probabilistic Bias Analysis. This includes things like understanding selection bias, unmeasured confounding and misclassification.\nThere are whole books written on this topic! So no general solutions here.\n\n4.4.1 Selection bias\n(Greenland 2014)\nWe only see people in our study if they meet some criterion (in other words, where S = 1), but we want to see everybody (i.e. people for whom S = 0)\n“But because we see only the relation of X to Y conditional on selection (S D 1), we must impute the unconditional relation of X to Y using probabilities of selection given what we do see (X and Y given S D 1).” In the Knox and colleagues example, this would require knowing the numbers of people who were observed by police but not stopped, in order to calculate the probabilities of selection into the stop dataset. However, we don’t know this - and it is hard to imagine a scenario where an analyst of an police administrative dataset would know this.\nEven if we do know this for our particular dataset, there is no guarantee that selection into the data would hold in every case that we might want to generalize our results to. As such we’d need to consider how differences between the study populations may have affected response and selection (e.g. would selection probabilities from a US study map onto a study in Manchester? How about one in Glasgow?)\n\n\n4.4.2 Confounding\nConfounding describes a situation where there’s something that we know affects the outcome we’re interested in and/or our independent variables, but we don’t have a measure for this. In criminology, we might have measures of police stops but not offending (.e.g from self-reports). Offending is likely to be a big - but not the only driver - of whether a person has contact with the police.\n\nbecause we do not see U, we must impute its values using probabilities (bets) about the values of U given what we do see (again, X and Y ).\n\nThe tipr approach is to unmeasured confounding - not just that we have a variable measured inaccurately, but that there is a key variable we haven’t measured",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selection effects, bias and so on</span>"
    ]
  },
  {
    "objectID": "selection-measurement.html#example",
    "href": "selection-measurement.html#example",
    "title": "4  Selection effects, bias and so on",
    "section": "4.6 Example",
    "text": "4.6 Example\n\nwork in example of using rcme data… but applying a different type of bias analysis?\n\n\n\n\n\nBlackwell, Matthew, James Honaker, and Gary King. 2017. “A Unified Approach to Measurement Error and Missing Data: Overview and Applications.” Sociological Methods & Research 46 (3): 303–41. https://doi.org/10.1177/0049124115585360.\n\n\nGaebler, Johann, William Cai, Guillaume Basse, Ravi Shroff, Sharad Goel, and Jennifer Hill. 2022. “A Causal Framework for Observational Studies of Discrimination.” Statistics and Public Policy 9 (1): 26–48. https://doi.org/10.1080/2330443X.2021.2024778.\n\n\nGreenland, Sander. 2014. “Sensitivity Analysis and Bias Analysis.” In Handbook of Epidemiology, edited by Wolfgang Ahrens and Iris Pigeot, 685–706. New York, NY: Springer. https://doi.org/10.1007/978-0-387-09834-0_60.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selection effects, bias and so on</span>"
    ]
  },
  {
    "objectID": "selection-measurement.html#misclassification",
    "href": "selection-measurement.html#misclassification",
    "title": "4  Selection effects, bias and so on",
    "section": "4.4 Misclassification?",
    "text": "4.4 Misclassification?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selection effects, bias and so on</span>"
    ]
  },
  {
    "objectID": "simulation.html#limits-to-simulation-approaches",
    "href": "simulation.html#limits-to-simulation-approaches",
    "title": "4  Simulation",
    "section": "4.2 Limits to simulation approaches",
    "text": "4.2 Limits to simulation approaches\nBut remember that our model is wrong!! (Greenland) This approach incorporates the uncertainty as expressed by your model’s standard errors. This still makes a load of assumptions - basically that we’ve fit the right model and that we had the right data. In more complex cases - like most real-world research - we might be fitting a much more complicated statistical model with non-linear effects and interaction terms and all sorts. As we’ll discuss in the next section, we might also want to cast a critical eye over the data that we are analysing before drawing our conclusions.\n\n\n\n\nHunter, James, and Andromachi Tseloni. 2016. “Equity, Justice and the Crime Drop: The Case of Burglary in England and Wales.” Crime Science 5 (1): 3. https://doi.org/10.1186/s40163-016-0051-z.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "simulation.html#add-clarify-example-here",
    "href": "simulation.html#add-clarify-example-here",
    "title": "4  Simulation",
    "section": "",
    "text": "get someone else to do the coding\nmore efficient\nexamples/tutorials online\nlink to marginal_effects?s",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "ethics.html#community-loss",
    "href": "ethics.html#community-loss",
    "title": "6  Ethics",
    "section": "6.3 community loss",
    "text": "6.3 community loss\nJessica Simes (Jessica T. Simes 2021) gives a good example of how we may want to come up with theoretically informed measures, or theoretically re-frame measures. Simes analysed imprisonment data from the state of Massachusets in the USA, including spatial regression of prison admission rates and how these relate to “racial demographics, social and economic disadvantage, arrest rates, and violent crime” (Jessica T. Simes 2018).\nAs part of this analysis Simes suggests that the cumulative years sentenced to residents of a particular neighbourhood be thought of as ‘community loss’. This is not (just?) an indicator of individual punishment histories, but reflects the chronic and long-term exposure to loss due to imprisonment in different neighbourhoods. This highlights the effects of imprisonment on the communities in which people who end up in prison lived prior to their imprisonment, rather than just focusing on the people who are currently in prison.\n\n\n\n\nSimes, Jessica T. 2021. Punishing Places: The Geography of Mass Imprisonment. Univ of California Press.\n\n\nSimes, Jessica T. 2018. “Place and Punishment: The Spatial Context of Mass Incarceration.” Journal of Quantitative Criminology 34 (2): 513–33. https://doi.org/10.1007/s10940-017-9344-y.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ethics</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#who-cares-about-data-provenance",
    "href": "types-of-data.html#who-cares-about-data-provenance",
    "title": "2  Types of criminological data",
    "section": "",
    "text": "“Why has the data been collected (and collected in this way)?\nHow has the data been collected and/or by whom or by what?\nWhat/who is included and what/who is excluded?\nWhat is the context for the data collection (routine activity, bespoke intervention, to meet a target)?\nHas the data been dis/aggregated or manipulated or cleaned in some other way to arrive at its present form?\nWhat are the relevant definitions and concepts that govern the data/data collection?”",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#other-forms-of-crime-data",
    "href": "types-of-data.html#other-forms-of-crime-data",
    "title": "2  Types of criminological data",
    "section": "2.5 Other forms of crime data",
    "text": "2.5 Other forms of crime data\n\n2.5.1 CVI data?\nhttps://www.scotland.police.uk/about-us/covid-19-police-scotland-response/enforcement-and-response-data/\n“In response to the introduction of The Health Protection (Coronavirus) (Restrictions) (Scotland) Regulations 2020 and Coronavirus Act 2020, Police Scotland developed a ‘Coronavirus Interventions’ (CVI) recording system. This system allowed Police Scotland to begin gathering data in relation to the public co-operation levels with the new legislation. This system relies on Police Officers manually updating the system with the co-operation level when they encounter an individual in contravention of the new legislation. Due to the manual input required to form this data set, the contents of this slide are indicative only. Actual figures will differ from those recorded on Crime Systems (please see further slide), may be subject to change, and cannot be considered Official Police Statistics. They do provide an indication of the public co-operation levels across Scotland.”\n“Notes on the CVI System The second data source was the Coronavirus Intervention (CVI) system, introduced by Police Scotland on 6 April 2020 in response to the introduction of the Coronavirus Act 2020 and associated Health Protection Regulations in Scotland.52 Data from the CVI were published throughout the pandemic on a weekly basis by Police Scotland until 17 November 2021. The main purpose of this system was to gather data on levels of public co-operation with the new Regulations, based on police officer interventions. The CVI system relies on manual updates from police officers about any interventions they have had with members of the public in respect of the legislation. It is not compulsory and, as a result, does not provide a comprehensive estimate of the total number of policing encounters. Nevertheless, it measures all policing-related activity (not just use of enforcement) and so provides a useful indicator of the relative use of different types of police activity in the context of the ‘Four Es strategy’, which was widely adopted by police forces across the UK in the context of the pandemic.53 To our knowledge, the CVI System is the only database of its kind to be used to measure the overall use of extended policing powers across the UK police forces from the start of the pandemic. Therefore, it provides an extremely useful source of complementary information to the FPN data. Comparison between FPN tickets and the CVI system Figure 22 shows a comparison of the number of tickets issued and the number recorded on the CVI as a seven-day rolling average between 27 March 2020 and 31 May 2021. The dark line shows the average number of FPNs issued, and the light line shows the average number recorded on Police Scotland’s CVI system. Both trend lines show four ‘phases’ of policing activity in relation to FPNs which are broadly reflective of the tightening and easing of restrictions in Scotland. The total number of FPN tickets actually issued (n = 20,410) was 20.9% higher than the number recorded on Police Scotland’s Coronavirus Intervention (CVI) system over the same period (n = 16,876)” https://www.law.ed.ac.uk/sites/default/files/2022-08/FPN%204th%20report%20-%20FINAL.pdf",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#triangulation-a-solution",
    "href": "types-of-data.html#triangulation-a-solution",
    "title": "2  Types of criminological data",
    "section": "2.6 Triangulation: a solution?",
    "text": "2.6 Triangulation: a solution?\nAtak - triangulation is good Buil-GIl says it’s best practice - … but need to assume that measures are of the same thing?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "general-linear-model.html#large-worlds-and-small-worlds",
    "href": "general-linear-model.html#large-worlds-and-small-worlds",
    "title": "3  The general linear model",
    "section": "",
    "text": "3.1.1 Big picture: two tribes of modellers?\n-   Economists versus epidemiologists",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The general linear model</span>"
    ]
  }
]