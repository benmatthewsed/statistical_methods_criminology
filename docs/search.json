[
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\nUntil now!\nA new change here.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Types of criminological data",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Atak, Kıvanç. 2020. “Beyond the Western Crime Drop:\nViolence, Property Offences, and the State in\nTurkey 19902016.” International\nJournal of Law, Crime and Justice 60 (March): 100373. https://doi.org/10.1016/j.ijlcj.2019.100373.\n\n\nBuil-Gil, David, Ian Brunton-Smith, Jose Pina-Sánchez, and Alexandru\nCernat. 2022. “Comparing Measurements of Violent Crime in Local\nCommunities: A Case Study in Islington,\nLondon.” Police Practice and Research 23\n(4): 489–506. https://doi.org/10.1080/15614263.2022.2047047.\n\n\nCarr-Hill, Roy. 2013. “Missing Millions and\nMeasuring Development Progress.” World\nDevelopment 46 (June): 30–44. https://doi.org/10.1016/j.worlddev.2012.12.017.\n\n\nGaebler, Johann, William Cai, Guillaume Basse, Ravi Shroff, Sharad Goel,\nand Jennifer Hill. 2022. “A Causal Framework for\nObservational Studies of\nDiscrimination.” Statistics and Public\nPolicy 9 (1): 26–48. https://doi.org/10.1080/2330443X.2021.2024778.\n\n\nGreenland, Sander. 2014. “Sensitivity Analysis and\nBias Analysis.” In Handbook of\nEpidemiology, edited by Wolfgang Ahrens and Iris\nPigeot, 685–706. New York, NY: Springer. https://doi.org/10.1007/978-0-387-09834-0_60.\n\n\nKnox, Dean, Will Lowe, and Jonathan Mummolo. 2020. “Administrative\nRecords Mask Racially Biased Policing.” American\nPolitical Science Review 114 (3): 619–37. https://doi.org/10.1017/S0003055420000039.\n\n\nScottish Women’s Aid. 2021. “Response to the Consultation on the\nScottish Crime and Justice Survey\n(SCJS), December 2021.”\nhttps://womensaid.scot/wp-content/uploads/2022/04/SWA-response-to-Scottish-Crime-and-Justice-Survey-consultation.pdf.\n\n\nSimes, Jessica T. 2021. Punishing Places: The\nGeography of Mass Imprisonment. Univ of\nCalifornia Press.\n\n\nSimes, Jessica T. 2018. “Place and Punishment:\nThe Spatial Context of Mass\nIncarceration.” Journal of Quantitative\nCriminology 34 (2): 513–33. https://doi.org/10.1007/s10940-017-9344-y.\n\n\nSimes, Jessica T., Brenden Beck, and John M. Eason. 2023.\n“Policing, Punishment, and Place:\nSpatial-Contextual Analyses of the Criminal Legal\nSystem.” Annual Review of Sociology 49 (1):\n221–40. https://doi.org/10.1146/annurev-soc-031021-035328.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Methods for Criminology",
    "section": "",
    "text": "Preface\nThis website contains the notes and R code for the NCRM workshop ‘Statistical Methods for Criminology’ which will run in September 2024.\nIt is very work in progress.\n\n\nAbout\nThis website contains the notes for the course. This is a combination of theoretical discussion and worked examples of fitting statistical models to criminological data and the issues that can arise when doing so.\nThe worked examples use ode in the R statistical language.\nThis website was built with Quarto using RStudio and is rendered with Github Pages.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "types-of-data.html",
    "href": "types-of-data.html",
    "title": "2  Types of criminological data",
    "section": "",
    "text": "2.1 Who cares about data provenance?\nTo conduct a useful analysis - the kind that might help you understand the real world - you need to understand how your data came about. As we’ll see, whether you are analysing a survey or police recorded crime data or convictions data or something else matters in how you conduct your analysis and interpret the results. You need to know the ‘generative story’1 about your data to analyse it properly.\nWhen working with criminological data we often know quite a lot about how the data (or if you like, the numbers in the spreadsheet in front of you) came to exist. Using this information - information that might be in metadata, or based on our theoretical knowledge of the world - can help us do better data analysis.\nHow exactly we incorporate this information will depend a lot on what data we’re working with and what the goals of our analysis are. There are no general solutions to what information we should incorporate and how we might do this, but in this workshop we’ll cover some scenarios that can arise in criminological research.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "intro.html#types-of-criminological-data",
    "href": "intro.html#types-of-criminological-data",
    "title": "1  Introduction",
    "section": "",
    "text": "Surveys\nPolice\nCourts // I’m sure there’s more\nWhat is the data provenance? What does this mean for my analysis?\nDo I need survey weights? Do I need to account for interactions with officers that aren’t recorded? Do I interpret convictions as a measure of offending?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#the-general-linear-model",
    "href": "intro.html#the-general-linear-model",
    "title": "1  Introduction",
    "section": "1.2 The general linear model",
    "text": "1.2 The general linear model\n\nBig picture: two tribes of modellers?\n\nEconomists versus epidemiologists\n\nWon’t include: mixed/multilevel/hierarchical/etc\nBut these might be relevant!\nFocus on general linear model to think about binary and count outcomes\n\nOver-dispersion what to do?\n\ninferential uncertainty versus outcome variability",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#measurement-error-and-selection-bias",
    "href": "intro.html#measurement-error-and-selection-bias",
    "title": "1  Introduction",
    "section": "1.3 Measurement error and selection bias",
    "text": "1.3 Measurement error and selection bias\n\nJose Pina Sanchez and measurement error\nWalby and volatility over time\nmeasurement error in general - from McElreath (can attenuate, but no guarantees)\nmeasurement error in controls - uh oh\nselection bias\n\nI guess I was thinking about the McElreath paper here/the Knox paper about conditioning on stop\nalso Sander Greenland about everything is conditional on selection into the study (e.g. mortality in prison)\nAnd also can do the Sander Greenland stuff on probabilistic bias analysis",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#ethics-of-working-with-criminological-data",
    "href": "intro.html#ethics-of-working-with-criminological-data",
    "title": "1  Introduction",
    "section": "1.5 Ethics of working with criminological data",
    "text": "1.5 Ethics of working with criminological data\n\nJessica Simes and community loss",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#how-does-an-event-become-a-crime-statistic",
    "href": "types-of-data.html#how-does-an-event-become-a-crime-statistic",
    "title": "3  Types of criminological data",
    "section": "3.3 How does an event become a crime statistic?",
    "text": "3.3 How does an event become a crime statistic?\n[add link to SG flow diagram]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#how-does-an-incident-end-up-as-a-court-record",
    "href": "types-of-data.html#how-does-an-incident-end-up-as-a-court-record",
    "title": "3  Types of criminological data",
    "section": "3.4 How does an incident end up as a court record?",
    "text": "3.4 How does an incident end up as a court record?\nCrime​\nArrest and charge​\nCourt​\nSentencing​",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#how-does-an-incident-get-logged-as-a-police-stop",
    "href": "types-of-data.html#how-does-an-incident-get-logged-as-a-police-stop",
    "title": "3  Types of criminological data",
    "section": "3.5 How does an incident get logged as a police stop?",
    "text": "3.5 How does an incident get logged as a police stop?\n(Knox and Mummolo)\n\nObservation\nEncouter\nStop",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#key-dilemma",
    "href": "types-of-data.html#key-dilemma",
    "title": "2  Types of criminological data",
    "section": "2.3 Key dilemma",
    "text": "2.3 Key dilemma\nDo official crime statistics reflect ‘behavioural’ trends in crime, or just the actions of the justice system?​(Kitsuse and Cicourel, 1963)\nHow you see this may depend on your theoretical persuasion (Simes, Beck, and Eason 2023)\nSometimes this is less of a dilemma when you have a comparable victim survey and you are interested in overall levels of crime (Buil-Gil et al. 2022). However, this is a challenge “outside consolidated western democracies where the range of available data is often limited” (Atak 2020)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#survey-data",
    "href": "types-of-data.html#survey-data",
    "title": "2  Types of criminological data",
    "section": "2.4 Survey data",
    "text": "2.4 Survey data\nMostly specialist secondary survey​\nScottish Crime and Justice Survey​\nCrime Survey for England and Wales​\nEquivalents in other countries, primarily in Western Europe, North America and Australasia ​\nSmaller geographical scale surveys such as The Mayor’s Office for Policing And Crime (MOPAC) Survey in London",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#victimization-surveys",
    "href": "types-of-data.html#victimization-surveys",
    "title": "2  Types of criminological data",
    "section": "2.5 Victimization surveys",
    "text": "2.5 Victimization surveys\nTypically ask people about their experiences of victimization in the last year​\nCan measure crime that isn’t reported to the police​\nUsually don’t ask about people’s offending behaviour​\nGood for measuring common crimes, bad for measuring rare crimes",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#how-does-a-person-get-selected-for-the-scjs",
    "href": "types-of-data.html#how-does-a-person-get-selected-for-the-scjs",
    "title": "2  Types of criminological data",
    "section": "2.6 How does a person get selected for the SCJS?",
    "text": "2.6 How does a person get selected for the SCJS?\nRandom sample of 10,000 postcodes in Scotland are contacted to take part​\nFor those who agree, one adult (age 16 or over) in each household is randomly selected for interview​\nTherefore, by design no:​\nChildren​\nHomeless people​\nPeople living in communal establishments\n“Moreover, in practice, household surveys typically under-represent: those in fragile, disjointed households; slum populations and areas posing security risks.” (Carr-Hill 2013)\n(Not going to talk about things like measurment equivalence in internaitonal surveys although that is a thing!)\nStandardization of surveys means it’s hard to reflect new forms of crime in established surveys – see cyber/enabled crime in CSEW​\nRegular changes to question wording means that time series analysis is compromised which is why only a small number of fraud and cyber questions were added to the CSEW​\nThis means that the new questions are only a limited measure of ‘cybercrime’\n\n2.6.0.1 Who is excluded?\nFor SCJS to be a measure of crime for all adults, not just all adults in private households, we need to make a key assumption that “the subset of the adult population not captured in the SCJS experience the same level of victimisation as adults in the household resident population”​\nBut this excludes people, students, people in prison, and those living in refuges​\n“Domestic abuse is the main cause of women’s homelessness in Scotland… All women living in Women’s Aid refuges have experienced domestic abuse and many will have experienced other forms of crime”\n(Scottish Women’s Aid 2021)\n\n\n\n\nAtak, Kıvanç. 2020. “Beyond the Western Crime Drop: Violence, Property Offences, and the State in Turkey 1990–2016.” International Journal of Law, Crime and Justice 60 (March): 100373. https://doi.org/10.1016/j.ijlcj.2019.100373.\n\n\nBuil-Gil, David, Ian Brunton-Smith, Jose Pina-Sánchez, and Alexandru Cernat. 2022. “Comparing Measurements of Violent Crime in Local Communities: A Case Study in Islington, London.” Police Practice and Research 23 (4): 489–506. https://doi.org/10.1080/15614263.2022.2047047.\n\n\nCarr-Hill, Roy. 2013. “Missing Millions and Measuring Development Progress.” World Development 46 (June): 30–44. https://doi.org/10.1016/j.worlddev.2012.12.017.\n\n\nKnox, Dean, Will Lowe, and Jonathan Mummolo. 2020. “Administrative Records Mask Racially Biased Policing.” American Political Science Review 114 (3): 619–37. https://doi.org/10.1017/S0003055420000039.\n\n\nSankaran, Kris, and Susan P. Holmes. 2023. “Generative Models: An Interdisciplinary Perspective.” Annual Review of Statistics and Its Application 10 (Volume 10, 2023): 325–52. https://doi.org/10.1146/annurev-statistics-033121-110134.\n\n\nScottish Women’s Aid. 2021. “Response to the Consultation on the Scottish Crime and Justice Survey (SCJS), December 2021.” https://womensaid.scot/wp-content/uploads/2022/04/SWA-response-to-Scottish-Crime-and-Justice-Survey-consultation.pdf.\n\n\nSimes, Jessica T., Brenden Beck, and John M. Eason. 2023. “Policing, Punishment, and Place: Spatial-Contextual Analyses of the Criminal Legal System.” Annual Review of Sociology 49 (1): 221–40. https://doi.org/10.1146/annurev-soc-031021-035328.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#who-is-excluded",
    "href": "types-of-data.html#who-is-excluded",
    "title": "3  Types of criminological data",
    "section": "3.10 Who is excluded?",
    "text": "3.10 Who is excluded?\nFor SCJS to be a measure of crime for all adults, not just all adults in private households, we need to make a key assumption that “the subset of the adult population not captured in the SCJS experience the same level of victimisation as adults in the household resident population”​\nBut this excludes people, students, people in prison, and those living in refuges​\n“Domestic abuse is the main cause of women’s homelessness in Scotland… All women living in Women’s Aid refuges have experienced domestic abuse and many will have experienced other forms of crime”\n\nFrom Handbook chapter - falling sample size, falling response rate and falling victimization all mean less ‘power’ in more recent SCJS sweeps\n\n“The reduction in survey response rates is a phenomenon that has been observed internationally (de Leeuw, Hox and Luiten, 2018), and there are particular concerns that it is the most marginalized in society (often the most prone to victimization) who are no longer responding to surveys (Savage and Burrows, 2009). Again, taking Scotland as an example, valid response rates to the SCJS fell from 71% in 2008/09 to 63% in 2019/20 (Saunders et al, 2021), with a urther reduction (following the Coronavirus pandemic) to just 47.3% in 2021/22 - the lowest response rate for any SCJS sweep since 2008/09 (Scottish Government 2023a). This issue has been compounded by reductions in the valid sample size for successive sweeps of the SCJS, which has reduced from 16,000 in 2008/09 to just 5,500 in the sweeps conducted since 2016/1714, largely in an effort to cut costs. Factoring in the large reduction in the prevalence of victimization (mentioned above), the stark reality is that the number of victims interviewed as part of the Scottish survey reduced from 2,786 in 2008/09 to just 639 in 2021/22. So, whilst the prevalence of crime fell by just over 50% (or in absolute terms, a fall of 10.4 percentage points), the number of survey respondents who had experienced at least one incident of crime has fallen by an astonishing 77%.”\nYou need to evaluate how useful a data source is in the context of your particular research question. e.g. you might be able to make an overall assessment of victimization for some social group but not look at a trend for that group, whilst you can look at trends for other groups. I guess this is curse of dimensionality. Or you might need a different model for some groups versus others/have to assume more.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#make-sure-the-data-is-right",
    "href": "types-of-data.html#make-sure-the-data-is-right",
    "title": "3  Types of criminological data",
    "section": "3.11 Make sure the data is right!!",
    "text": "3.11 Make sure the data is right!!\nhttps://x.com/jkangbrown/status/1790416534776562157",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "general-linear-model.html",
    "href": "general-linear-model.html",
    "title": "3  The general linear model",
    "section": "",
    "text": "3.1 Large worlds and small worlds\nRichard McElreath (McElreath 2020) talks about the ‘small world’ of the model and the ‘large world’ that we actually live in. Our spreadsheets and coefficients can only summarize the small world for us, and omit some of the complexity of the large world. This is fine if all we want to do is provide summaries of the the numbers in our spreadsheets. But as soon as we want to understand the large world we can run in to problems if all we focus on are the rows and columns in front of us. We often need to bring our understanding of the large world - for example, how an incident becomes a crime - to bear during statistical modelling. In this session we’ll overview two ways in which our understanding of the ‘large world’ might influence how we interpret our results from the ‘small world’: measurement error and selection effects.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The general linear model</span>"
    ]
  },
  {
    "objectID": "selection-measurement.html",
    "href": "selection-measurement.html",
    "title": "4  Selection effects, bias and so on",
    "section": "",
    "text": "4.1 Large worlds and small worlds\nRichard McElreath (McElreath 2020) talks about the ‘small world’ of the model and the ‘large world’ that we actually live in. Our spreadsheets and coefficients can only summarize the small world for us, and omit some of the complexity of the large world. This is fine if all we want to do is provide summaries of the the numbers in our spreadsheets. But as soon as we want to understand the large world we can run in to problems if all we focus on are the rows and columns in front of us. We often need to bring our understanding of the large world - for example, how an incident becomes a crime - to bear during statistical modelling. In this session we’ll overview two ways in which our understanding of the ‘large world’ might influence how we interpret our results from the ‘small world’: measurement error and selection effects.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selection effects, bias and so on</span>"
    ]
  },
  {
    "objectID": "selection-measurement.html#solutions",
    "href": "selection-measurement.html#solutions",
    "title": "4  Selection effects, bias and so on",
    "section": "4.4 Solutions?",
    "text": "4.4 Solutions?\nKnox et al. (2020) suggest some technical fixes, but emphasise that - if we are interested in using statistical models to identify causal relationships there is no general solution that can guarantee that coefficients in a regression model will have valid causal interpretations based on administrative data derived from police records. The key thing is thinking through the process by which the dataset was constructed, and conveying this to your reader.\nmaybe get the students to play about with the data in the dataverse?https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/KFQOCV",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selection effects, bias and so on</span>"
    ]
  },
  {
    "objectID": "selection-measurement.html#probabilistic-bias-analysis",
    "href": "selection-measurement.html#probabilistic-bias-analysis",
    "title": "4  Selection effects, bias and so on",
    "section": "4.5 Probabilistic Bias Analysis",
    "text": "4.5 Probabilistic Bias Analysis\nWhat Knox et al. suggest is part of a set of approaches called Probabilistic Bias Analysis. This includes things like understanding selection bias, unmeasured confounding and misclassification.\nThere are whole books written on this topic! So no general solutions here.\n\n4.5.1 Selection bias\n(Greenland 2014)\nWe only see people in our study if they meet some criterion (in other words, where S = 1), but we want to see everybody (i.e. people for whom S = 0)\n“But because we see only the relation of X to Y conditional on selection (S D 1), we must impute the unconditional relation of X to Y using probabilities of selection given what we do see (X and Y given S D 1).” In the Knox and colleagues example, this would require knowing the numbers of people who were observed by police but not stopped, in order to calculate the probabilities of selection into the stop dataset. However, we don’t know this - and it is hard to imagine a scenario where an analyst of an police administrative dataset would know this.\nEven if we do know this for our particular dataset, there is no guarantee that selection into the data would hold in every case that we might want to generalize our results to. As such we’d need to consider how differences between the study populations may have affected response and selection (e.g. would selection probabilities from a US study map onto a study in Manchester? How about one in Glasgow?)\n\n\n4.5.2 Confounding\nConfounding describes a situation where there’s something that we know affects the outcome we’re interested in and/or our independent variables, but we don’t have a measure for this. In criminology, we might have measures of police stops but not offending (.e.g from self-reports). Offending is likely to be a big - but not the only driver - of whether a person has contact with the police.\n\nbecause we do not see U, we must impute its values using probabilities (bets) about the values of U given what we do see (again, X and Y ).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selection effects, bias and so on</span>"
    ]
  },
  {
    "objectID": "selection-measurement.html#in-general",
    "href": "selection-measurement.html#in-general",
    "title": "4  Selection effects, bias and so on",
    "section": "4.6 In general",
    "text": "4.6 In general\nNeed to make assumptions about the magnitude of the bias to implement any of the technical fixes. Fine. But where does this information come from?\n“The preceding approach assumes that U is a known confounder (e.g., a smoking indicator) that was unmeasured in the study in question but has been previously identified and subject to study in relation to disease if not exposure. If instead U represents an unspecified, unknown confounder, then the entire sensitivity exercise will remain far more speculative. Nonetheless, decomposition of the bias factor can still be successful in demonstrating that only implausibly strong confounder or selection effects can account for a strong observed association. Cornfield et al. (1959) is considered a landmark study in which such an approach was used to examine claims that the smoking-lung cancer relation might be attributable to confounding”\n\nso this is based on the idea tat we can identify an “implausibly strong” confounder, which is reasonable.\n\nIs the small world enough? How do we talk about this? e.g. if all we’ve done is analysed convictions data do we talk about offending, or just conviction?\n“Despite these considerations, there is no basis for mandating a bias analysis of every study or even most studies. For example, bias analysis is superfluous when conventional intervals show that no useful conclusion could be drawn from the study even if it were perfect apart from random error. More generally, rather than providing a bias analysis, a study may provide greater service by refraining from inference; instead it can focus on carefully reporting its design, conduct, and data in great detail to facilitate pooling and meta-analysis (Greenland et al. 2004). Inferences are best based on a more complete account of evidence than can be provided in a single study report, and thus the effort of bias analysis is more justifiable in research synthesis (Turner et al. 2009; Welton et al. 2009). Even there, bias analysis becomes essential only when doing risk assessment or when authors claim to offer near-definitive conclusions.” (Greenland 2014, p703)\n… so you only need to bother with this stuff if you ‘claim to offer near-definitive conclusions’. Is your study likely to contribute to a meta analysis? Or in other words, when you are moving between the small world and the large world.\nMeans humility when making policy recommendations!!\n\n\n\n\nGaebler, Johann, William Cai, Guillaume Basse, Ravi Shroff, Sharad Goel, and Jennifer Hill. 2022. “A Causal Framework for Observational Studies of Discrimination.” Statistics and Public Policy 9 (1): 26–48. https://doi.org/10.1080/2330443X.2021.2024778.\n\n\nGreenland, Sander. 2014. “Sensitivity Analysis and Bias Analysis.” In Handbook of Epidemiology, edited by Wolfgang Ahrens and Iris Pigeot, 685–706. New York, NY: Springer. https://doi.org/10.1007/978-0-387-09834-0_60.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and STAN. CRC Press.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selection effects, bias and so on</span>"
    ]
  },
  {
    "objectID": "intro.html#using-models-to-describe-quantities-of-interest",
    "href": "intro.html#using-models-to-describe-quantities-of-interest",
    "title": "1  Introduction",
    "section": "1.4 Using models to describe quantities of interest",
    "text": "1.4 Using models to describe quantities of interest\n\nGary King and general principle\nsecondary motivation of what is your estimand?\ngeneral principle of adjusted predictive comparisons (and also g-estimation)\nspecific example of victimization divides as a DQI",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "general-linear-model.html#assumptions-and-p-values",
    "href": "general-linear-model.html#assumptions-and-p-values",
    "title": "3  The general linear model",
    "section": "3.7 Assumptions and p-values",
    "text": "3.7 Assumptions and p-values\nhttps://bristoluniversitypressdigital.com/edcollchap/book/9781529232073/ch014.xml\nFocus on effect size measures instead?\nThink about populations hard (https://benmatthewsed.github.io/what_to_do_odds_ratios/what_to_do_odds_ratios.html#/title-slide)\n\n3.7.1 An example of thinking about populations and generalization\nThis question came from the Policing the Pandemic in Scotland project with excellent colleagues Dr Vicky Gorton and Prof Susan McVie\nWe linked data on all (well, most) fines received for breaching the Covid regulations in Scotland between 27 March 2020 to 31 May 2021 with information on recipients’ health (service use) and (some) social circumstances (I’m not going to go into detail about this)\nWe also have the same information on a comparison group of matched controls (matched by age, sex, Local Authority and SIMD decile)\nWe want to know if people with more ‘vulnerability’ (read - health service use) are more likely than others to have received a Covid fine (FPN)\nHaving done all this, I actually don’t think we’ll use this in our paper. Thinking hard about the population that we’re interested in made me wonder…\n… and what’s wrong with an odds ratio of 35 anyway?\nThis is an accurate description of our dataset!\nIf the problem is that we don’t think a result this extreme would generalize to another ‘sample’ from the sample population - with close to every person who received an FPN do we even have any issues of generalizability (we have basically 100% of the relevant people, minus matching error)?\nInstead of generalizability, I think we have either a massive issue with transportability/external validity (Degtiar and Rose 2023), or we have no issue at all\nIt seems nonsensical to suggest that these results would apply to another country during Covid or another pandemic (countries were very different in their responses)\nThe results for Lockdown One in Scotland don’t even generalize to Lockdown Two - we show that in our analysis!\n\n\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and STAN. CRC Press.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The general linear model</span>"
    ]
  },
  {
    "objectID": "selection-measurement.html#draw-from-pina-sanchez",
    "href": "selection-measurement.html#draw-from-pina-sanchez",
    "title": "Selection effects, bias and so on",
    "section": "Draw from Pina sanchez",
    "text": "Draw from Pina sanchez\nhttps://josepinasanchez.uk/wp-content/uploads/2021/12/rmef_measurement-error_b.pdf\nfrom https://josepinasanchez.uk/short-courses/",
    "crumbs": [
      "Selection effects, bias and so on"
    ]
  },
  {
    "objectID": "selection-measurement.html#measurement-error",
    "href": "selection-measurement.html#measurement-error",
    "title": "4  Selection effects, bias and so on",
    "section": "4.2 Measurement error",
    "text": "4.2 Measurement error\nThe standard linear model assumes that all variables are measured perfectly (or in other words, with no error).\nIn practice we know this is unlikely, particularly with crime data. For example, we know that police recorded crime data is not a perfect measure of the amount of crime ‘out there’ in society. As we have discussed already, not all crimes are reported to the police, not all incidents which are reported are recorded as crimes and so on.\nIf we treat recorded crime data\nMeasurement error can impact an analysis in pretty much any conceiveable way, depending on the type, magnitude and source of measurement error - whether the error is in the outcome, or in a key independent variable, or in a control variable. It may bias your regression coefficients, meaning that your results are valid and in reality there is a stronger association between predictor and outcome that you have observed. It may not bias your regression coefficients at all but just impact the precision of your results. Other than in simple scenarios we may not know what impact it is having.\nMore examples here\n\n4.2.1 What to do about it?\nWhat’s more is that it’s not entirely clear what to do about it.\nOne way to approach this, if we know or can reasonably approximate the model for the measurement error then we can use Bayesian methods to jointly estimate a model for our observations and the measurement error. This is easier said than done! Bayesian methods are extremely flexible and allow the researcher to model to specify a model for the measurement error which is estimated jointly with the model for their outcome. This relies on knowing what the right model for the measurement error should be. It also relies on fitting a Bayesian model to your data which comes with its own set of challenges.\nPina-Sanchez has written about measurement error in crime.\nOne approach is to use Bayesian methods.\nPina Sanchez gave a workshop on Bayesian adjustments for measurement error, and you can find the materials here: https://josepinasanchez.uk/short-courses/\nhttps://josepinasanchez.uk/wp-content/uploads/2021/12/rmef_measurement-error_b.pdf\nfrom https://josepinasanchez.uk/short-courses/\n\n\n4.2.2 SIMEX\nA less involved option involves assessment measurement error through simulation. The process here is to fit the model to the data as observed and try to figure out what the coefficients would be if there was no measurement error in the data. The simex R package lets you simulate new versions of your dataset with more and more measurement error. By looking to see how your coefficients change after re-fitting your model with increasing measurement error you can project backwards to what the coefficients would be with zero measurement error. Neat!\n\n\n4.2.3 rcme\nPina-Sanchez and colleagues have written an R package that can conduct sensitivity analysis for some types of measurement error common to working with police recorded crime.\n\nWork through their example here? https://osf.io/preprints/socarxiv/sbc8w\n\nOpen questions - what about survey data? Models other than linear models?\n\n\n4.2.4 Key takeaway\n\nThink hard, be honest.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selection effects, bias and so on</span>"
    ]
  },
  {
    "objectID": "simulation.html",
    "href": "simulation.html",
    "title": "4  Simulation",
    "section": "",
    "text": "Sometimes when we fit a statistical model we just want to read off a coefficient in the model and that is our key result. However, sometimes we want to calculate some other quantity from our model and focus on that instead. For general applications of this approach see Gelman and Pardoe (2007) and King et al. (2000).\nFor example, Hunter and Tseloni use the results of a fitted regression model to calculate a measure they call ‘Victimization Divide’. This measure is a way to describe how victimization inequality has changed over time - a very important thing for criminologists to care about.\nThis measure is defined as\n(ratio of victimization rates in year 2 - 1) - (ratio of victimization rates in year 2 - 1) / (ratio of victimization rates in year one - 1)\nthis is analagous to exploring the percentage change in victimization inequality between two comparison years.\nHowever, if these ratios of rates come from a statistical model they will also come with some uncertainty measure, such as a standard error. In that case it’s not quite so clear how to incorporate this uncertainty into the calculation of the VD. One way to do this is to use the regression model to simulate a bunch of coefficients values and then calculate the VD for each one.\nMatthews and McVie (2024; see also Matthews 2024) demonstrate this process. The table below shows the prevalence of victimization (for all crime types) for men and women as reported in the Crime Survey for England and Wales for 2015 and 2020 (Office for National Statistics, n.d.). We can see that the prevalence of victimization was higher for men than women in both years, and that it increased for men (by 3.0 percentage points) and women (by 3.6 percentage points) between 2015 and 2020.\nWe can fit a simple regression model to the data in each year to calculate the ratio of the odds of being a victim for men and women. Model 1 shows a statistically significant difference for men (compared to women) in 2015, with men having 11% greater odds of being a victim of crime. In contrast, Model 2 finds that men had a 5% greater odds of being a victim of crime than women in 2020; however, this difference does not meet the 95% threshold for statistical significance.\nCalculating the VD for these two results, based on the odds ratios from the two models, shows that victimization inequality decreased by 52% between the two years. Victimiztion inequality fell by more than half!\nHowever, this does not factor the uncertainty in these odds ratios into our results. To investigate this we can simulate 1,000 sets of coefficients from the models’ results. Using 10,000 simulations from the models’ results, we get 95% intervals for the VD of -0.95 and 0.22. Whilst our most of our simulations do indicate that victimization inequality has declined, this would not be considered ‘statistically significant’ at the usual 95% threshold.\nThe beauty of this simulation approach described by King et al (2000) is that it generalizes to any DQI, such as VD, and to any regression model specification. Say that instead of the VD were interested in the absolute difference in predicted victimization after controlling for other factors (like a marginal effect). Or maybe we have fitted a count model and we want to know the number of people reporting 2 or more victimization incidents - we can calculate this from our simulations whilst incorporating (some) uncertainty into our estimates.\nBut remember that our model is wrong!! (Greenland) This approach incorporates the uncertainty as expressed by your model’s standard errors. As we’ve seen in the discussions about measurement error and sensitivity analysis, there may be other sources of uncertainty around our results.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Simulation</span>"
    ]
  },
  {
    "objectID": "general-linear-model.html#a-note-on-bespoke-models",
    "href": "general-linear-model.html#a-note-on-bespoke-models",
    "title": "3  The general linear model",
    "section": "3.6 A note on bespoke models",
    "text": "3.6 A note on bespoke models\nI am extremely partial to bespoke models. If you have the time I would recommend reading and watching all the Statistical Rethinking lectures - this gives an introduction into building your own models tailored to your specific data and problems. But that will take weeks and weeks and we are only here until five.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The general linear model</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#geography",
    "href": "types-of-data.html#geography",
    "title": "2  Types of criminological data",
    "section": "2.2 Geography",
    "text": "2.2 Geography\nMostly scope is national, but not always​\nSome local surveys​(suchas MOPAC/Islington Crime Survey)\nCan get data on trends for [individual police forces in the UK] (https://data.police.uk/data/), or [victimization survey data aggreted to police division level within Scotland] (https://scotland.shinyapps.io/sg-scottish-crime-justice-survey/)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "ethics.html",
    "href": "ethics.html",
    "title": "6  Ethics",
    "section": "",
    "text": "6.1 Reproducible research practices?\nMake sure the data is right!!\nhttps://github.com/jkangbrown/when_police_replication",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ethics</span>"
    ]
  },
  {
    "objectID": "ethics.html#framing",
    "href": "ethics.html#framing",
    "title": "6  Ethics",
    "section": "6.2 Framing",
    "text": "6.2 Framing\nMore conceptually, it’s important to think about how we frame the results of any analysis.\nThree visualizations from Data Feminism\n\nlanguage use\nproviding necessary context?\ndeficit narrative\nthe description of your charts is theoretically informed\n\n\n6.2.1 community loss\nJessica Simes (Jessica T. Simes 2021) gives a good example of how we may want to come up with theoretically informed measures, or theoretically re-frame measures. Simes analysed imprisonment data from the state of Massachusets in the USA, including spatial regression of prison admission rates and how these relate to “racial demographics, social and economic disadvantage, arrest rates, and violent crime” (Jessica T. Simes 2018).\nAs part of this analysis Simes suggests that the cumulative years sentenced to residents of a particular neighbourhood be thought of as ‘community loss’. This is not (just?) an indicator of individual punishment histories, but reflects the chronic and long-term exposure to loss due to imprisonment in different neighbourhoods. This highlights the effects of imprisonment on the communities in which people who end up in prison lived prior to their imprisonment, rather than just focusing on the people who are currently in prison.\n\n\n\n\nSimes, Jessica T. 2021. Punishing Places: The Geography of Mass Imprisonment. Univ of California Press.\n\n\nSimes, Jessica T. 2018. “Place and Punishment: The Spatial Context of Mass Incarceration.” Journal of Quantitative Criminology 34 (2): 513–33. https://doi.org/10.1007/s10940-017-9344-y.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ethics</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#generative-stories-for-common-types-of-crime-data",
    "href": "types-of-data.html#generative-stories-for-common-types-of-crime-data",
    "title": "2  Types of criminological data",
    "section": "2.2 Generative stories for common types of crime data",
    "text": "2.2 Generative stories for common types of crime data\n\n2.2.1 How does an event become a crime statistic?\n[add link to SG flow diagram]\n\n\n2.2.2 How does an incident end up as a court record?\nCrime​\nArrest and charge​\nCourt​\nSentencing​\n\n\n2.2.3 How does an incident get logged as a police stop?\n(Knox, Lowe, and Mummolo 2020)\n\nObservation\nEncouter\nStop\n\n\n\n2.2.4 CVI data?\nhttps://www.scotland.police.uk/about-us/covid-19-police-scotland-response/enforcement-and-response-data/",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  },
  {
    "objectID": "general-linear-model.html#count-data",
    "href": "general-linear-model.html#count-data",
    "title": "3  The general linear model",
    "section": "3.4 Count data",
    "text": "3.4 Count data\nThe foundational model for count data is the Poisson model:\n\\[\n\\begin{align*}\ny_i \\sim & {Poisson} (\\lambda) \\\\\n{log(\\lambda)} & = \\alpha + \\beta (x_i),\n\\end{align*}\n\\]\nNow there is only one parameter (lambda; \\(\\lambda\\)) that we are modelling, unlike with linear regression. This means that in Poisson models the mean and the variance are assumed to be the same (or put another way, that they are both direct functions of \\(\\lambda\\)).\nThe key feature of count data is that it is integers (i.e. whole numbers) only and they are stricly positive - you can’t get negative counts. Pretty much all aggregated administrative data about crime in its raw form will be count data. This might be counts of recorded crime, counts of people released from prison and so on. These data might be re-expressed as rates per 1,000 population, but before this they are counts.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The general linear model</span>"
    ]
  },
  {
    "objectID": "general-linear-model.html#why-not-just-lm",
    "href": "general-linear-model.html#why-not-just-lm",
    "title": "3  The general linear model",
    "section": "3.5 why not just lm?",
    "text": "3.5 why not just lm?\n\ntwo tribes\n\nif all you care about is the average difference then you can just use ‘Simple Mean Difference’\nyou might be an economist\nthere are lots of other interesting quesitons we might care about (e.g. modelling dispersion?)\n\n\n\n3.5.1 Specific problems with GLMs\n\nclassic problem - over-dispersion\npoisson assumes mean and variance are the same (only one term in the model)\nso what? mostly under-estimates the standard error\np-values are too optimistic\nyou need to think about why your data are over-dispersed\ntake from Hilbe (distinct zeros? ZIP; generic solution; NB?)\nZIP can have different predictors for zeros than count part\nyou can also have different predictors for dispersion and rate parameter in NB if you want\nif all you care about is your standard errors you can use quasi-poisson (same point estimates as poisson but with ‘empirical’ SEs - similar to using robust standard errors)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The general linear model</span>"
    ]
  },
  {
    "objectID": "general-linear-model.html#logistic-regression",
    "href": "general-linear-model.html#logistic-regression",
    "title": "3  The general linear model",
    "section": "3.3 Logistic regression",
    "text": "3.3 Logistic regression\nFor logistic regression we have:\n\\[\n\\begin{align*}\ny_i \\sim & {Binomial} (n, p_i) \\\\\n{logit(p_i)} & = \\alpha + \\beta (x_i),\n\\end{align*}\n\\] for logistic regression, \\(n\\) = 1, and we are just interested in modelling \\(p_i\\).\nThese kinds of models are very common in the social sciences, including in criminology. We might want to model whether someone is a victim of crime or not, or whether the person has been convicted of a crime in a given year, or whether they are confident in the police or not… and so on and so on. The nice thing about this model formulation is that the \\({logit}\\) link function makes sure that all the probabilities the model estimates are between 0 and 1. Strictly speaking we don’t need to do this (see the linear probability model), but it’s nice to avoid results that obviously don’t make sense, like negative probabilities and such.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The general linear model</span>"
    ]
  },
  {
    "objectID": "general-linear-model.html#intro-to-glm",
    "href": "general-linear-model.html#intro-to-glm",
    "title": "3  The general linear model",
    "section": "3.2 Intro to GLM",
    "text": "3.2 Intro to GLM\nRecommended watching: https://www.youtube.com/watch?v=qbxNf4iqJPo&t=1215s\nIntroduction to LM\n\nStochastic (or random) component\nSystematic component\nLink function\n\n(I adapted this notation from Solomon Kurz https://bookdown.org/content/4857/god-spiked-the-integers.html#poisson-regression)\n\\[\n\\begin{align*}\ny_i \\sim & {Distribution} (\\theta_i, \\phi) \\\\\n{f(\\theta_i)} & = \\alpha + \\beta (x_i - \\bar x),\n\\end{align*}\n\\]\nwhere \\(\\theta_i\\) is the parameter of interest (e.g., the probability of 1 in a Binomial distribution) and \\(\\phi\\) is a placeholder for any other parameters necessary for the likelihood but not typically of primary substantive interest (e.g., \\(\\sigma\\) in conventional Gaussian models). The \\(f(\\cdot)\\) portion is the link function.\nFor the linear model, we have:\n\\[\n\\begin{align*}\ny_i \\sim & {Normal} (\\theta_i, \\sigma) \\\\\n{Identity(\\theta_i)} & = \\alpha + \\beta (x_i - \\bar x),\n\\end{align*}\n\\]\n\nan example here?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The general linear model</span>"
    ]
  },
  {
    "objectID": "selection-measurement.html#selection-effects",
    "href": "selection-measurement.html#selection-effects",
    "title": "4  Selection effects, bias and so on",
    "section": "4.3 Selection effects",
    "text": "4.3 Selection effects\nOne use of regression models is to identify ‘causal’ effects of predictors on outcomes.\nSome links on where to read more about causal inference? Maybe here \nImagine that we want to know whether police are racially biased in how they treat members of the public. One way to assess this is by using data from the police about the outcomes of their interactions with the public.\nFor example, we might want to know if people from minority ethnic backgrounds more likely to be arrested after a stop than people from white backgrounds (Knox et al)\nPolice collect data on stops - why not just run a regression on these data to see if people from minority ethnic backgrounds are more likely to be stopped?\nThe problem is we can’t just rely on data about police stops - “if police racially discriminate when choosing whom to investigate, analyses using administrative records to estimate racial discrimination in police behavior are statistically biased, and many quantities of interest are unidentified—even among investigated individuals—absent strong and untestable assumptions.”\nWe’re going to hear a lot about ‘strong and untestable assumptions’.\n“when there is any racial discrimination in the decision to detain civilians—a decision that determines which encounters appear in police administrative data at all—then estimates of the effect of civilian race on subsequent police behavior are biased absent additional data and/or strong and untestable assumptions.”\n[INSERT FIGURE 2 FROM KNOX]\n\n\n\nKnox et al (2020) FIGURE 2. Principal Strata and Observed Police–Civilian Encounters. Notes: The figure displays the four principal strata that comprise police–civilian encounters based on how the mediator M (whether a civilian is stopped by police) responds to treatment D (whether the civilian is a racial minority). Minorities in the “always stop” and anti-minority racial stop strata, highlighted in red, are stopped by police and, thus, appear in police administrative data. Likewise, white civilians in the “always-stop” and anti-white racial stop strata, highlighted in blue, appear in police data. “Never stop” encounters are unobserved. Because white and nonwhite encounters are drawn from different principal strata, the two groups are incomparable and estimates of causal quantities using observed encounters will be statistically biased absent additional assumptions.\n\n\nIf you only analyse data that are the result of police stops then your results will be biased. To analyse data on police stops to estimate racial bias, you also need to know the total number of encounters (for each ethnic group) – that is, including encounters that did not lead to a stop.\nOthers (Gaebler et al. 2022)suggest that maybe you can identify some aspects of discrimination in administrative data. This would be discrimination at some point in the process, not total discrimination. It’s really important to be clear about what it is you want to know – do you care about total discrimination, or discrimination in a particular part of the process (e.g. court sentencing and not policing?).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selection effects, bias and so on</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#footnotes",
    "href": "types-of-data.html#footnotes",
    "title": "2  Types of criminological data",
    "section": "",
    "text": "‘Generative modelling’ is - depressingly - a term that means different things to different audiences (Sankaran and Holmes 2023). Michael Betancourt talks about ‘narratively generative’ models (betancourtWhatProbabilisticStory?), which is a terminology I quite like - we can tell a story about how the data came to be and this can influence the model/s we fit.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of criminological data</span>"
    ]
  }
]