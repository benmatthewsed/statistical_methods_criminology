[
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\nUntil now!\nA new change here.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Types of criminological data",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "statistical_methods_criminology",
    "section": "",
    "text": "Preface\nThis website contains the notes and R code for the NCRM workshop ‘Statistical Methods for Criminology’ run in September 2024.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "types-of-data.html",
    "href": "types-of-data.html",
    "title": "Types of criminological data",
    "section": "",
    "text": "Scope\nMostly scope is national, but not always​\nSome local surveys​\nCan get data on trends for individual police forces, or Local Authorities etc",
    "crumbs": [
      "Types of criminological data"
    ]
  },
  {
    "objectID": "intro.html#types-of-criminological-data",
    "href": "intro.html#types-of-criminological-data",
    "title": "1  Introduction",
    "section": "",
    "text": "Surveys\nPolice\nCourts // I’m sure there’s more\nWhat is the data provenance? What does this mean for my analysis?\nDo I need survey weights? Do I need to account for interactions with officers that aren’t recorded? Do I interpret convictions as a measure of offending?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#the-general-linear-model",
    "href": "intro.html#the-general-linear-model",
    "title": "1  Introduction",
    "section": "1.2 The general linear model",
    "text": "1.2 The general linear model\n\nBig picture: two tribes of modellers?\n\nEconomists versus epidemiologists\n\nWon’t include: mixed/multilevel/hierarchical/etc\nBut these might be relevant!\nFocus on general linear model to think about binary and count outcomes\n\nOver-dispersion what to do?\n\ninferential uncertainty versus outcome variability",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#measurement-error-and-selection-bias",
    "href": "intro.html#measurement-error-and-selection-bias",
    "title": "1  Introduction",
    "section": "1.3 Measurement error and selection bias",
    "text": "1.3 Measurement error and selection bias\n\nJose Pina Sanchez and measurement error\nWalby and volatility over time\nmeasurement error in general - from McElreath (can attenuate, but no guarantees)\nmeasurement error in controls - uh oh\nselection bias\n\nI guess I was thinking about the McElreath paper here/the Knox paper about conditioning on stop\nalso Sander Greenland about everything is conditional on selection into the study (e.g. mortality in prison)\nAnd also can do the Sander Greenland stuff on probabilistic bias analysis\n\nUsing models to describe quantities of interest\nGary King and general principle\nsecondary motivation of what is your estimand?\ngeneral principle of adjusted predictive comparisons (and also g-estimation)\nspecific example of victimization divides as a DQI",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#ethics-of-working-with-criminological-data",
    "href": "intro.html#ethics-of-working-with-criminological-data",
    "title": "1  Introduction",
    "section": "1.4 Ethics of working with criminological data",
    "text": "1.4 Ethics of working with criminological data\n\nJessica Simes and community loss",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "types-of-data.html#how-does-an-event-become-a-crime-statistic",
    "href": "types-of-data.html#how-does-an-event-become-a-crime-statistic",
    "title": "Types of criminological data",
    "section": "How does an event become a crime statistic?",
    "text": "How does an event become a crime statistic?\n[add link to SG flow diagram]",
    "crumbs": [
      "Types of criminological data"
    ]
  },
  {
    "objectID": "types-of-data.html#how-does-an-incident-end-up-as-a-court-record",
    "href": "types-of-data.html#how-does-an-incident-end-up-as-a-court-record",
    "title": "Types of criminological data",
    "section": "How does an incident end up as a court record?",
    "text": "How does an incident end up as a court record?\nCrime​\nArrest and charge​\nCourt​\nSentencing​",
    "crumbs": [
      "Types of criminological data"
    ]
  },
  {
    "objectID": "types-of-data.html#how-does-an-incident-get-logged-as-a-police-stop",
    "href": "types-of-data.html#how-does-an-incident-get-logged-as-a-police-stop",
    "title": "Types of criminological data",
    "section": "How does an incident get logged as a police stop?",
    "text": "How does an incident get logged as a police stop?\n(Knox and Mummolo)\n\nObservation\nEncouter\nStop",
    "crumbs": [
      "Types of criminological data"
    ]
  },
  {
    "objectID": "types-of-data.html#key-dilemma",
    "href": "types-of-data.html#key-dilemma",
    "title": "Types of criminological data",
    "section": "Key dilemma",
    "text": "Key dilemma\nDo official crime statistics reflect ‘behavioural’ trends in crime, or just the actions of the justice system?​(Kitsuse and Cicourel, 1963)\nSometimes this is less of a dilemma when you have a comparable victim survey and you are interested in overall levels of crime, but is a challenge “outside consolidated western democracies where the range of available data is often limited” (Atak, K. (2020) Beyond the western crime drop: Violence, property offences, and the state in Turkey 1990–2016, International Journal of Law, Crime and Justice (60) https://doi.org/10.1016/j.ijlcj.2019.100373 )",
    "crumbs": [
      "Types of criminological data"
    ]
  },
  {
    "objectID": "types-of-data.html#survey-data",
    "href": "types-of-data.html#survey-data",
    "title": "Types of criminological data",
    "section": "Survey data",
    "text": "Survey data\nMostly specialist secondary survey​\nScottish Crime and Justice Survey​\nCrime Survey for England and Wales​\nEquivalents in other countries, primarily in Western Europe, North America and Australasia ​\nSmaller geographical scale surveys such as The Mayor’s Office for Policing And Crime (MOPAC) Survey in London",
    "crumbs": [
      "Types of criminological data"
    ]
  },
  {
    "objectID": "types-of-data.html#victimization-surveys",
    "href": "types-of-data.html#victimization-surveys",
    "title": "Types of criminological data",
    "section": "Victimization surveys",
    "text": "Victimization surveys\nTypically ask people about their experiences of victimization in the last year​\nCan measure crime that isn’t reported to the police​\nUsually don’t ask about people’s offending behaviour​\nGood for measuring common crimes, bad for measuring rare crimes",
    "crumbs": [
      "Types of criminological data"
    ]
  },
  {
    "objectID": "types-of-data.html#how-does-a-person-get-selected-for-the-scjs",
    "href": "types-of-data.html#how-does-a-person-get-selected-for-the-scjs",
    "title": "Types of criminological data",
    "section": "How does a person get selected for the SCJS?",
    "text": "How does a person get selected for the SCJS?\nRandom sample of 10,000 postcodes in Scotland are contacted to take part​\nFor those who agree, one adult (age 16 or over) in each household is randomly selected for interview​\nTherefore, by design no:​\nChildren​\nHomeless people​\nPeople living in communal establishments\n“Moreover, in practice, household surveys typically under-represent: those in fragile, disjointed households; slum populations and areas posing security risks.” Carr-Hill, R. (2013). Missing Millions and Measuring Development Progress. World Development, 46, 30–44. https://doi.org/10.1016/j.worlddev.2012.12.017​\n(Not going to talk about things like measurment equivalence in internaitonal surveys although that is a thing!)\nStandardization of surveys means it’s hard to reflect new forms of crime in established surveys – see cyber/enabled crime in CSEW​\nRegular changes to question wording means that time series analysis is compromised which is why only a small number of fraud and cyber questions were added to the CSEW​\nThis means that the new questions are only a limited measure of ‘cybercrime’",
    "crumbs": [
      "Types of criminological data"
    ]
  },
  {
    "objectID": "types-of-data.html#who-is-excluded",
    "href": "types-of-data.html#who-is-excluded",
    "title": "Types of criminological data",
    "section": "Who is excluded?",
    "text": "Who is excluded?\nFor SCJS to be a measure of crime for all adults, not just all adults in private households, we need to make a key assumption that “the subset of the adult population not captured in the SCJS experience the same level of victimisation as adults in the household resident population”​\nBut this excludes people, students, people in prison, and those living in refuges​\n“Domestic abuse is the main cause of women’s homelessness in Scotland… All women living in Women’s Aid refuges have experienced domestic abuse and many will have experienced other forms of crime”\n\nFrom Handbook chapter - falling sample size, falling response rate and falling victimization all mean less ‘power’ in more recent SCJS sweeps\n\n“The reduction in survey response rates is a phenomenon that has been observed internationally (de Leeuw, Hox and Luiten, 2018), and there are particular concerns that it is the most marginalized in society (often the most prone to victimization) who are no longer responding to surveys (Savage and Burrows, 2009). Again, taking Scotland as an example, valid response rates to the SCJS fell from 71% in 2008/09 to 63% in 2019/20 (Saunders et al, 2021), with a urther reduction (following the Coronavirus pandemic) to just 47.3% in 2021/22 - the lowest response rate for any SCJS sweep since 2008/09 (Scottish Government 2023a). This issue has been compounded by reductions in the valid sample size for successive sweeps of the SCJS, which has reduced from 16,000 in 2008/09 to just 5,500 in the sweeps conducted since 2016/1714, largely in an effort to cut costs. Factoring in the large reduction in the prevalence of victimization (mentioned above), the stark reality is that the number of victims interviewed as part of the Scottish survey reduced from 2,786 in 2008/09 to just 639 in 2021/22. So, whilst the prevalence of crime fell by just over 50% (or in absolute terms, a fall of 10.4 percentage points), the number of survey respondents who had experienced at least one incident of crime has fallen by an astonishing 77%.”\nYou need to evaluate how useful a data source is in the context of your particular research question. e.g. you might be able to make an overall assessment of victimization for some social group but not look at a trend for that group, whilst you can look at trends for other groups. I guess this is curse of dimensionality. Or you might need a different model for some groups versus others/have to assume more.",
    "crumbs": [
      "Types of criminological data"
    ]
  },
  {
    "objectID": "types-of-data.html#make-sure-the-data-is-right",
    "href": "types-of-data.html#make-sure-the-data-is-right",
    "title": "Types of criminological data",
    "section": "Make sure the data is right!!",
    "text": "Make sure the data is right!!\nhttps://x.com/jkangbrown/status/1790416534776562157",
    "crumbs": [
      "Types of criminological data"
    ]
  },
  {
    "objectID": "general-linear-model.html",
    "href": "general-linear-model.html",
    "title": "general linear model",
    "section": "",
    "text": "Intro to GLM\n\n\nBinary data\n\nvictim or not? offender or not? confident or not?\n[take from gary king]\n\n\n\nCount data\n\nintegers only! stricly positive!\nwhy not just lm?\ntwo tribes\n\nif all you care about is the average difference then you can just use ‘Simple Mean Difference’\nyou might be an economist\nthere are lots of other interesting quesitons we might care about (e.g. modelling dispersion?)\n\nclassic problem - over-dispersion\npoisson assumes mean and variance are the same (only one term in the model)\nso what? mostly under-estimates the standard error\np-values are too optimistic\nyou need to think about why your data are over-dispersed\ntake from Hilbe (distinct zeros? ZIP; generic solution; NB?)\nZIP can have different predictors for zeros than count part\nyou can also have different predictors for dispersion and rate parameter in NB if you want\nif all you care about is your standard errors you can use quasi-poisson (same point estimates as poisson but with ‘empirical’ SEs - similar to using robust standard errors)",
    "crumbs": [
      "general linear model"
    ]
  },
  {
    "objectID": "selection-measurement.html",
    "href": "selection-measurement.html",
    "title": "Selection effects, bias and so on",
    "section": "",
    "text": "An example\nImagine that we want to know whether police are racially biased in how they treat members of the public. One way to assess this is by using data from the police about the outcomes of their interactions with the public.\nFor example, we might want to know if people from minority ethnic backgrounds more likely to be arrested after a stop than people from white backgrounds (Knox et al)\nPolice collect data on stops - why not just run a regression on these data to see if people from minority ethnic backgrounds are more likely to be stopped?\nThe problem is we can’t just rely on data about police stops - “if police racially discriminate when choosing whom to investigate, analyses using administrative records to estimate racial discrimination in police behavior are statistically biased, and many quantities of interest are unidentified—even among investigated individuals—absent strong and untestable assumptions.”\nWe’re going to hear a lot about ‘strong and untestable assumptions’.\n“when there is any racial discrimination in the decision to detain civilians—a decision that determines which encounters appear in police administrative data at all—then estimates of the effect of civilian race on subsequent police behavior are biased absent additional data and/or strong and untestable assumptions.”\n[INSERT FIGURE 2 FROM KNOX]\nIf you only analyse data that are the result of police stops then your results will be biased. To analyse data on police stops to estimate racial bias, you also need to know the total number of encounters (for each ethnic group) – that is, including encounters that did not lead to a stop.\nOthers (Gaebler et al.) suggest that maybe you can identify some aspects of discrimination in administrative data. This would be discrimination at some point in the process, not total discrimination. It’s really important to be clear about what it is you want to know – do you care about total discrimination, or discrimination in a particular part of the process (e.g. court sentencing and not policing?).",
    "crumbs": [
      "Selection effects, bias and so on"
    ]
  },
  {
    "objectID": "selection-measurement.html#solutions",
    "href": "selection-measurement.html#solutions",
    "title": "Selection effects, bias and so on",
    "section": "Solutions?",
    "text": "Solutions?\nKnox et al. (2020) suggest some technical fixes. The key thing is thinking through the process by which the dataset was constructed, and conveying this to your reader.",
    "crumbs": [
      "Selection effects, bias and so on"
    ]
  },
  {
    "objectID": "selection-measurement.html#probabilistic-bias-analysis",
    "href": "selection-measurement.html#probabilistic-bias-analysis",
    "title": "Selection effects, bias and so on",
    "section": "Probabilistic Bias Analysis",
    "text": "Probabilistic Bias Analysis\nWhat Knox et al. suggest is part of a set of approaches called Probabilistic Bias Analysis. This includes things like understanding selection bias, unmeasured confounding and misclassification.\nThere are whole books written on this topic! So no general solutions here.\n\nSelection bias\nWe only see people in our study if they meet some criterion (in other words, where S = 1), but we want to see everybody (i.e. people for whom S = 0)\n“But because we see only the relation of X to Y conditional on selection (S D 1), we must impute the unconditional relation of X to Y using probabilities of selection given what we do see (X and Y given S D 1).” - https://link.springer.com/referenceworkentry/10.1007/978-0-387-09834-0_60\nBiasS D 1 might be estimated as the ratio of estimates without and with information from initial non-responders on whom data was later obtained (“call-back survey” information) from studies reporting such information (e.g., Hatch et al. 2000). Even with such information, however, concerns about generalization across studies must be addressed by considering how differences between the study populations may have affected response and selection.\n\n\nConfounding\nThere’s something that we know affects the outcome we’re interested in and/or our independent variables, but we don’t have a measure for this. In criminology, we might have measures of police stops but not offending (.e.g from self-reports). Offending is likely to be a big - but not the only driver - of whether a person has contact with the police.\n\nbecause we do not see U, we must impute its values using probabilities (bets) about the values of U given what we do see (again, X and Y ).",
    "crumbs": [
      "Selection effects, bias and so on"
    ]
  },
  {
    "objectID": "selection-measurement.html#in-general",
    "href": "selection-measurement.html#in-general",
    "title": "Selection effects, bias and so on",
    "section": "In general",
    "text": "In general\nNeed to make assumptions about the magnitude of the bias to implement any of the technical fixes. Fine. But where does this information come from?\n“he preceding approach assumes that U is a known confounder (e.g., a smoking indicator) that was unmeasured in the study in question but has been previously identified and subject to study in relation to disease if not exposure. If instead U represents an unspecified, unknown confounder, then the entire sensitivity exercise will remain far more speculative. Nonetheless, decomposition of the bias factor can still be successful in demonstrating that only implausibly strong confounder or selection effects can account for a strong observed association. Cornfield et al. (1959) is considered a landmark study in which such an approach was used to examine claims that the smoking-lung cancer relation might be attributable to confounding”\n\nso this is based on the idea tat we can identify an “implausibly strong” confounder, which is reasonable.",
    "crumbs": [
      "Selection effects, bias and so on"
    ]
  }
]